{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sSbQIvnPx0W0"
   },
   "source": [
    "# word2vec Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sUjoOSJCx0W2",
    "outputId": "a98b5ac6-1673-422c-c7c4-dd91d6cf17cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import gensim as gs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import nltk\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "from nltk.tokenize import sent_tokenize as st\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import logging\n",
    "import re\n",
    "import sys\n",
    "import random\n",
    "from collections import Counter\n",
    "from tensorflow.contrib import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Bidirectional, Dense,LSTM,Input,Activation,Add,TimeDistributed,\\\n",
    "Permute,Flatten,RepeatVector,merge,Lambda,Multiply,Reshape\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential,Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vav79cEmx0W9"
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "histPath = ''\n",
    "#load training data\n",
    "with open(histPath+'train.txt', \"rb\") as f1, open(histPath+'val.txt', \"rb\") as f2, open(histPath+'test.txt', \"rb\") as f3: \n",
    "    trainX, trainY = pickle.load(f1)\n",
    "    valX, valY = pickle.load(f2)\n",
    "    testX, testY = pickle.load(f3)\n",
    "#load dictionaries\n",
    "with open(histPath+'word2idx_master.json', 'r') as f1, open(histPath+'idx2word_master.json', 'r') as f2:\n",
    "    word2idx = json.load(f1)\n",
    "    idx2word = json.load(f2)\n",
    "\n",
    "#load embedding matrix\n",
    "embeddMatrix = np.load(histPath+'embeddMatrix_word2vec_0510.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ADJqSYpIx0W_"
   },
   "outputs": [],
   "source": [
    "#params for model training\n",
    "seed = 209\n",
    "p_W, p_U, p_dense, p_emb, weight_decay = 0, 0, 0, 0, 0\n",
    "LR = 1e-4\n",
    "batch_size = 32\n",
    "\n",
    "num_train_batches = len(trainX) // batch_size\n",
    "num_val_samples = len(valX) + len(trainX) - batch_size*num_train_batches\n",
    "num_val_batches = len(valX) // batch_size\n",
    "total_entries = (num_train_batches + num_val_batches)*batch_size\n",
    "\n",
    "#maximum length for title \n",
    "# tMaxLen = 20\n",
    "tMaxLen = 250\n",
    "#maximum length for abstract\n",
    "aMaxLen = 250\n",
    "#total maximum length\n",
    "maxlen = tMaxLen + aMaxLen\n",
    "\n",
    "batch_norm=False\n",
    "\n",
    "embeddDim = embeddMatrix.shape[1]\n",
    "nUnique = embeddMatrix.shape[0]\n",
    "hidden_units= embeddDim\n",
    "\n",
    "learning_rate = 0.002\n",
    "clip_norm = 1.0\n",
    "# regularizer = l2(weight_decay) if weight_decay else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PjLBQTBJx0XC"
   },
   "source": [
    "---\n",
    "\n",
    "## I. Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wy8dEpxKx0XD"
   },
   "outputs": [],
   "source": [
    "#padding function for abstracts\n",
    "def padAbstract(x, maxL = aMaxLen, dictionary = word2idx):\n",
    "    n = len(x)\n",
    "    if n > maxL:\n",
    "        x = x[-maxL:]\n",
    "        n = maxL\n",
    "    return [dictionary['_']]*(maxL - n) + x + [dictionary['*']]\n",
    "\n",
    "#build generator for model\n",
    "def generator(trainX, trainY, batch_size = batch_size, \n",
    "              nb_batches = None, model = None, seed = seed):\n",
    "    \n",
    "    #UNDERSTAND THIS\n",
    "    c = nb_batches if nb_batches else 0\n",
    "    while True:\n",
    "        titles = list()\n",
    "        abstracts = list()\n",
    "        if nb_batches and c >= nb_batches:\n",
    "            c = 0\n",
    "        new_seed = random.randint(0, sys.maxsize)\n",
    "        random.seed(c+123456789+seed)\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            a = random.randint(0,len(trainX)-1)\n",
    "            \n",
    "            #random shuffling of data\n",
    "            abstract = trainX[a]\n",
    "            s = random.randint(min(aMaxLen,len(abstract)), max(aMaxLen,len(abstract)))\n",
    "            abstracts.append(abstract[:s])\n",
    "            \n",
    "            title = trainY[a]\n",
    "            s = random.randint(min(tMaxLen,len(title)), max(tMaxLen,len(title)))\n",
    "            titles.append(title[:s])\n",
    "\n",
    "        # undo the seeding before we yield in order not to affect the caller\n",
    "        c+= 1\n",
    "        random.seed(new_seed)\n",
    "\n",
    "        yield conv_seq_labels(abstracts, titles)\n",
    "\n",
    "#pad sequence and convert title to labels\n",
    "def conv_seq_labels(abstracts, titles, nflips = None, model = None, dictionary = word2idx):\n",
    "    \"\"\"abstract and titles are converted to padded input vectors. Titles are one-hot encoded to labels.\"\"\"\n",
    "    batch_size = len(titles)\n",
    "    \n",
    "    \n",
    "    x = [padAbstract(a)+t for a,t in zip(abstracts, titles)] \n",
    "    x = sequence.pad_sequences(x, maxlen = maxlen, value = dictionary['_'], \n",
    "                               padding = 'post', truncating = 'post')\n",
    "        \n",
    "    y = np.zeros((batch_size, tMaxLen, nUnique))\n",
    "    for i, it in enumerate(titles):\n",
    "        it = it + [dictionary['*']] + [dictionary['_']]*tMaxLen  # output does have a eos at end\n",
    "        it = it[:tMaxLen]\n",
    "        y[i,:,:] = np_utils.to_categorical(it, nUnique)\n",
    "        \n",
    "    #The 3 inputs are abstract, title starting with eos and a one-hot encoding of the title categorical variables.\n",
    "    return [x[:,:aMaxLen],x[:,aMaxLen:]], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "Qu8vqCWfx0XF",
    "outputId": "ea483079-9a74-4c2f-ae97-3d68efcfb768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 250) (32, 250) (32, 250, 32471)\n",
      "Abstract  :  ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'with', 'the', 'increase', 'in', 'available', 'data', 'parallel', 'machine', 'learning', 'has', '<ign>', '<ign>', 'become', 'an', 'increasingly', 'pressing', 'problem.', 'in', 'this', 'paper', 'we', 'present', '<ign>', '<ign>', 'the', 'first', 'parallel', 'stochastic', 'gradient', 'descent', 'algorithm', 'including', 'a', '<ign>', '<ign>', 'detailed', 'analysis', 'and', 'experimental', 'evidence.', 'unlike', 'prior', 'work', 'on', '<ign>', '<ign>', 'parallel', 'optimization', 'algorithms', 'our', '<ign>', '<ign>', 'variant', 'comes', 'with', 'parallel', 'acceleration', 'guarantees', 'and', 'it', 'poses', 'no', '<ign>', '<ign>', 'overly', 'tight', 'latency', 'constraints,', 'which', 'might', 'only', 'be', 'available', 'in', '<ign>', '<ign>', 'the', 'multicore', 'setting.', 'our', 'analysis', 'introduces', 'a', 'novel', 'proof', '<ign>', '<ign>', 'technique', '<ign>', 'contractive', 'mappings', 'to', 'quantify', 'the', '<ign>', '<ign>', 'speed', 'of', 'convergence', 'of', 'parameter', 'distributions', 'to', 'their', 'asymptotic', '<ign>', '<ign>', 'limits.', 'as', 'a', 'side', 'effect', 'this', 'answers', 'the', 'question', 'of', 'how', 'quickly', '<ign>', '<ign>', 'stochastic', 'gradient', 'descent', 'algorithms', 'reach', 'the', 'asymptotically', '<ign>', '<ign>', 'normal', 'regime.']\n",
      "Title  :  ['*', 'parallelized', 'stochastic', 'gradient', 'descent', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n"
     ]
    }
   ],
   "source": [
    "#check generator\n",
    "check = next(generator(trainX, trainY, batch_size = batch_size))\n",
    "print(check[0][0].shape,check[0][1].shape,check[1].shape)\n",
    "print(\"Abstract  : \", [idx2word[str(i)] for i in check[0][0][1]])\n",
    "print(\"Title  : \", [idx2word[str(i)] for i in check[0][1][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LsDy6pxNx0XJ"
   },
   "outputs": [],
   "source": [
    "#generator for training and validation\n",
    "genTrain = generator(trainX, trainY, batch_size = batch_size)\n",
    "genVal =  generator(valX, valY, nb_batches = len(valX)// batch_size, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A-9jfFGRx0XM"
   },
   "source": [
    "---\n",
    "\n",
    "## II. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4FETS5-o0w4O"
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M0SuCA_hx0XN"
   },
   "outputs": [],
   "source": [
    "#encoder\n",
    "def getModel(num_epochs, genTrain, genVal, embeddMatrix, learning_rate, clip_norm,\n",
    "             encoder_shape = aMaxLen, decoder_shape = tMaxLen, \n",
    "             nUnique = nUnique, embeddDim = embeddDim, hidden_units = hidden_units):\n",
    "    \n",
    "    #ENCODER\n",
    "    #input shape as the vector of sequence, with length padded to 250\n",
    "    encoder_inputs = Input(shape = (encoder_shape, ), name = 'encoder_input')\n",
    "    \n",
    "    encoder_embedding = Embedding(nUnique, embeddDim, \n",
    "                                  input_length = encoder_shape, \n",
    "                                  weights = [embeddMatrix],\n",
    "                                  mask_zero = True,\n",
    "                                  name = 'encoder_embedd')(encoder_inputs)\n",
    "    \n",
    "    encoder_lstm = Bidirectional(LSTM(hidden_units, dropout_U = 0.2,\n",
    "                                      dropout_W = 0.2 , return_state=True))\n",
    "    \n",
    "    encoder_outputs, f_h, f_c, b_h, b_c = encoder_lstm(encoder_embedding)\n",
    "    \n",
    "    state_hfinal=Add()([f_h, b_h])\n",
    "    state_cfinal=Add()([f_c, b_c])\n",
    "    \n",
    "    encoder_states = [state_hfinal,state_cfinal]\n",
    "        \n",
    "    #DECODER\n",
    "    decoder_inputs = Input(shape = (decoder_shape, ), name = 'decoder_input')\n",
    "    \n",
    "    decoder_embedding = Embedding(nUnique, embeddDim, \n",
    "                                  input_length = decoder_shape, \n",
    "                                  weights = [embeddMatrix],\n",
    "                                  mask_zero = True,\n",
    "                                  name = 'decoder_embedd')\n",
    "    \n",
    "    decoder_lstm = LSTM(hidden_units,return_sequences = True, return_state=True)\n",
    "    \n",
    "    decoder_outputs, s_h, s_c = decoder_lstm(decoder_embedding(decoder_inputs), initial_state = encoder_states)    \n",
    "    decoder_dense = Dense(decoder_shape, activation='linear')\n",
    "    decoder_time_distributed = TimeDistributed(Dense(nUnique,\n",
    "                                                     name = 'decoder_timedistributed'))\n",
    "    decoder_activation = Activation('softmax', name = 'decoder_activation')\n",
    "    decoder_outputs = decoder_activation(decoder_time_distributed(decoder_outputs))\n",
    "    \n",
    "    #MODEL\n",
    "    model = Model(inputs = [encoder_inputs,decoder_inputs], outputs = decoder_outputs) \n",
    "    rmsprop = RMSprop(lr = learning_rate, clipnorm = clip_norm)\n",
    "    model.compile(loss = 'categorical_crossentropy',optimizer = rmsprop)\n",
    "    return model, 0, 0\n",
    "    #FIT MODEL\n",
    "#     model.fit_generator(genTrain,\n",
    "#                         steps_per_epoch = num_train_batches,\n",
    "#                         epochs=num_epochs, \n",
    "#                         validation_data = genVal,\n",
    "#                         validation_steps = num_val_batches)\n",
    "    \n",
    "#     #ENCODER MODEL\n",
    "#     encoder_model = Model(encoder_inputs,encoder_states)\n",
    "    \n",
    "#     #DECODER MODEL\n",
    "#     decoder_state_inputs_h = Input(shape=(hidden_units,))\n",
    "#     decoder_state_inputs_c = Input(shape=(hidden_units,)) \n",
    "#     decoder_state_inputs = [decoder_state_inputs_h, decoder_state_inputs_c]\n",
    "#     decoder_outputs, decoder_state_h, decoder_state_c = decoder_lstm(decoder_embedding(decoder_inputs),\n",
    "#                                                                      initial_state = decoder_state_inputs)\n",
    "#     decoder_states = [decoder_state_h, decoder_state_c]\n",
    "#     decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "#     decoder_model = Model([decoder_inputs] + decoder_state_inputs,\n",
    "#                           [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    #return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "Gkx0XSiRx0XQ",
    "outputId": "a4c3bbbc-0d02-45a2-b6b6-6af17a45f58d"
   },
   "outputs": [],
   "source": [
    "mod, encoder, decoder = getModel(15, genTrain, genVal, embeddMatrix, learning_rate, clip_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "104/104 [==============================] - 381s 4s/step - loss: 6.7924 - val_loss: 6.4424\n",
      "Epoch 2/15\n",
      "104/104 [==============================] - 365s 4s/step - loss: 6.0360 - val_loss: 6.2462\n",
      "Epoch 3/15\n",
      "104/104 [==============================] - 367s 4s/step - loss: 5.7731 - val_loss: 6.1418\n",
      "Epoch 4/15\n",
      "104/104 [==============================] - 377s 4s/step - loss: 5.5584 - val_loss: 6.0337\n",
      "Epoch 5/15\n",
      "104/104 [==============================] - 369s 4s/step - loss: 5.3389 - val_loss: 5.9530\n",
      "Epoch 6/15\n",
      "104/104 [==============================] - 375s 4s/step - loss: 5.1533 - val_loss: 5.9167\n",
      "Epoch 7/15\n",
      "104/104 [==============================] - 370s 4s/step - loss: 5.0003 - val_loss: 5.8666\n",
      "Epoch 8/15\n",
      "104/104 [==============================] - 364s 4s/step - loss: 4.8257 - val_loss: 5.8629\n",
      "Epoch 9/15\n",
      "104/104 [==============================] - 366s 4s/step - loss: 4.6572 - val_loss: 5.8545\n",
      "Epoch 10/15\n",
      "104/104 [==============================] - 374s 4s/step - loss: 4.4918 - val_loss: 5.8508\n",
      "Epoch 11/15\n",
      "104/104 [==============================] - 364s 4s/step - loss: 4.3215 - val_loss: 5.8996\n",
      "Epoch 12/15\n",
      "104/104 [==============================] - 371s 4s/step - loss: 4.2258 - val_loss: 5.9271\n",
      "Epoch 13/15\n",
      "104/104 [==============================] - 369s 4s/step - loss: 4.0888 - val_loss: 5.9581\n",
      "Epoch 14/15\n",
      "104/104 [==============================] - 370s 4s/step - loss: 3.9373 - val_loss: 6.0191\n",
      "Epoch 15/15\n",
      "104/104 [==============================] - 364s 4s/step - loss: 3.8518 - val_loss: 6.0481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcf68c63b00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rnn.fit_generator(genTrain,\n",
    "#                     steps_per_epoch = num_train_batches,\n",
    "#                     epochs=15, \n",
    "#                     validation_data = genVal,\n",
    "#                     validation_steps = num_val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save models\n",
    "mod.save_weights('rnn_weights_0508.h5')\n",
    "# encoder.save('encoder.h5')\n",
    "# decoder.save('decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 250)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_embedd (Embedding)      (None, 250, 100)     3247100     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      (None, 250)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, 200), (None, 160800      encoder_embedd[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_embedd (Embedding)      (None, 250, 100)     3247100     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 100)          0           bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 100)          0           bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 250, 100), ( 80400       decoder_embedd[0][0]             \n",
      "                                                                 add_1[0][0]                      \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 250, 32471)   3279571     lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder_activation (Activation) (None, 250, 32471)   0           time_distributed_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 10,014,971\n",
      "Trainable params: 10,014,971\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mod.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.load_weights('word2vec_weights_0510.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(model, seq, idx2word, maxLen, \n",
    "                  num_iteration, greedy = True, latitude = 5):\n",
    "    '''\n",
    "    Prediction for a given sequence. \n",
    "    \n",
    "    Parameters:\n",
    "    ===========\n",
    "    1)model: rnn model\n",
    "    2)seq: a single abstract, should be a vector of length 250\n",
    "    3)maxLen: maximum length of predicted abstract\n",
    "    4)num_iteration\n",
    "    5)idx2word: dictionary for index to word\n",
    "    6)greedy: default to greedy search predictions, otherwise beam search\n",
    "    7)latitude: for greedy search, how many top words to consider for random choice\n",
    "    '''\n",
    "    \n",
    "    #cache list of prediction\n",
    "    prediction = list()\n",
    "    #initiate title to be a vector of zeros\n",
    "    init = np.zeros(maxLen)\n",
    "             \n",
    "    #for maximum prediction length\n",
    "    for i in range(num_iteration):\n",
    "        #get prediction probabilities for all unique words\n",
    "        predRNN = model.predict([np.reshape(seq, (1, 250)), init.reshape(1, 250)])\n",
    "        \n",
    "        if greedy:\n",
    "\n",
    "            #update next title vector to be the predicted vector\n",
    "            idx = np.argmax(predRNN[0, i])\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            #get top number of words\n",
    "            idxV = np.argsort(predRNN[0, i])[-latitude: ]\n",
    "            #randomly choose from the top words\n",
    "            idx = np.random.choice(idxV)\n",
    "            if i == 0:\n",
    "                while idx == 1:\n",
    "                    idx = np.random.choice(idxV)\n",
    "            else:\n",
    "                while idx == prediction[i-1]:\n",
    "                    idx = np.random.choice(idxV)\n",
    "        \n",
    "        #index to word\n",
    "        word = idx2word[str(idx)]\n",
    "        init[i] = idx\n",
    "        #if eos tag is predicted\n",
    "        #break out of loop\n",
    "        if idx == 1:\n",
    "            break\n",
    "        prediction.append(word)\n",
    "            \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check prediction \n",
    "check = testX.copy()\n",
    "check = sequence.pad_sequences(check, 250, value = word2idx['_'], \n",
    "                               padding = 'pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dual',\n",
       " 'inhibitory',\n",
       " 'mechanisms',\n",
       " 'for',\n",
       " 'definition',\n",
       " 'of',\n",
       " 'receptive',\n",
       " 'field',\n",
       " 'characteristics',\n",
       " 'in',\n",
       " 'a',\n",
       " 'cat',\n",
       " 'striate',\n",
       " 'cortex']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of seq2seq prediction\n",
    "#true title\n",
    "[idx2word[str(m)] for m in testY[40]]\n",
    "\n",
    "# true abstract\n",
    "# [idx2word[str(m)] for m in check[40]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,    75,   264,   646,\n",
       "           4,    58,  3979,  3980,  7134,  1576,   392,  3590,   420,\n",
       "        4288,   977,  2719,   431,  6172,    19,   802, 23449, 12328,\n",
       "          10, 24526,  5591,  1806, 24527,   642,   248,   431,  4705,\n",
       "        8788,  7747,    51, 24528,     7,  5039,  8753,  6083,    58,\n",
       "        5510,   136,    10,  1586, 24529,   122,   431, 22000,  2693,\n",
       "           7,  5694,  8062,   122,  1727,   431,    32,    75, 24530,\n",
       "        6843,  4097,  7954,     4,   392,  1391,  2527,   157,  5591,\n",
       "        1391,  5382,    27,  6419,  5709,  7400,  6244,   478,  3744,\n",
       "         642, 24531,    10,   814,   386,   122,  1559,   149,  2209,\n",
       "           7,  7177,   977,  1704,   455,  1975,     7,    10,   153,\n",
       "         386,   122,  6691, 16474,   977,  1928,  6419,   249,     4,\n",
       "        4121,  1573,    75,   573,  1164,  6271,   122,  5709,   478,\n",
       "         102,   558,  5915,  7537, 24532,     2,     2], dtype=int32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neural',\n",
       " 'implementation',\n",
       " 'of',\n",
       " 'the',\n",
       " 'lateral',\n",
       " 'inhibition',\n",
       " 'in',\n",
       " 'the',\n",
       " 'vestibulo-ocular']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction\n",
    "\n",
    "#     1)model: rnn model\n",
    "#     2)seq: a single abstract, should be a vector of length 250\n",
    "#     3)maxLen: maximum length of predicted title\n",
    "#     4)idx2word: dictionary for index to word\n",
    "#     5)greedy: default to greedy search predictions, otherwise beam search\n",
    "#     6)latitude: for greedy search, how many top words to consider for random choice\n",
    "        \n",
    "check_pred = getPrediction(mod, check[40], idx2word, 250, 20)\n",
    "check_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relative import of rouge_evaluation\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "    \n",
    "from myeval import rouge_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_f, temp_p, temp_r = rouge_evaluation(check_pred, [idx2word[str(m)] for m in testY[40]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18181817719008275"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "rnn_model.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
