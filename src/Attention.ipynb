{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import gensim as gs\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "from nltk.tokenize import sent_tokenize as st\n",
    "\n",
    "import Levenshtein\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# keras\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Dense,LSTM,Input,Activation,Add,TimeDistributed,Permute,Flatten,RepeatVector\n",
    "from keras.layers import merge,Lambda,Multiply,Reshape, Bidirectional\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential,Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# useful libraries\n",
    "import logging\n",
    "import re\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# utils\n",
    "import utils, utils_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globals\n",
    "seed = 42\n",
    "embedding_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7241, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1987</td>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>1994</td>\n",
       "      <td>Bayesian Query Construction for Neural Network...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>1994</td>\n",
       "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                              title event_type  \\\n",
       "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
       "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
       "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
       "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
       "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
       "\n",
       "                                            pdf_name          abstract  \\\n",
       "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
       "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
       "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
       "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
       "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
       "\n",
       "                                          paper_text  \n",
       "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
       "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
       "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
       "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
       "4  Neural Network Ensembles, Cross\\nValidation, a...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers = pd.read_csv('../data/papers.csv')\n",
    "print(papers.shape)\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7174, 7)\n",
      "(4659, 8)\n"
     ]
    }
   ],
   "source": [
    "papers = utils_updated.preprocessing(papers)\n",
    "papers = papers.dropna(subset=['abstract'])\n",
    "print(papers.shape)\n",
    "papers['a_len'] = [len(abst.split()) for abst in papers['abstract']]\n",
    "papers = papers[papers['a_len'] < 250]\n",
    "print(papers.shape)\n",
    "titles, abstracts = list(papers['title']),list(papers['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract :  the paper presents a rapid speaker-normalization technique based on neural network spectral mapping. the neural network is used as a front-end of a continuous speech recognition system (speakerdependent, hmm-based) to normalize the input acoustic data from a new speaker. the spectral difference between speakers can be reduced using a limited amount of new acoustic data (40 phonetically rich sentences). recognition error of phone units from the acoustic-phonetic continuous speech corpus apasci is decreased with an adaptability ratio of 25%. we used local basis networks of elliptical gaussian kernels, with recursive allocation of units and on-line optimization of parameters (gran model). for this application, the model included a linear term. the results compare favorably with multivariate linear mapping based on constrained orthonormal transformations.  1\n",
      "Title :  connectionist speaker normalization with generalized resource allocating networks\n",
      "<class 'str'> <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "i = 10\n",
    "print('Abstract : ',abstracts[i])\n",
    "print('Title : ', titles[i])\n",
    "print(type(titles[0]),type(abstracts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(lst):\n",
    "    vocabcount = Counter(w for txt in lst for w in txt.split())\n",
    "    vocab = map(lambda x: x[0], sorted(vocabcount.items(), key=lambda x: -x[1]))\n",
    "    return list(vocab), vocabcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words :  ['the', 'of', 'a', 'and', 'to', 'in', 'we', 'for', 'is', 'that', 'on', 'with', 'this', 'learning', 'as', 'are', 'an', 'by', 'our', 'can', 'which', 'from', 'be', 'model', 'algorithm', 'data', 'show', 'using', 'it', 'neural', 'problem', 'models', 'method', 'such', 'these', 'based', 'approach', 'results', 'algorithms', 'new', 'network', 'propose', 'or', 'has', 'networks', 'have', 'methods', 'number', 'between', 'also']\n"
     ]
    }
   ],
   "source": [
    "vocab, vocabcount = get_vocab(titles+abstracts)\n",
    "print(\"Most common words : \", vocab[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([vocabcount[w] for w in vocab]);\n",
    "plt.gca().set_xscale(\"log\", nonposx='clip')\n",
    "plt.gca().set_yscale(\"log\", nonposy='clip')\n",
    "plt.title('word distribution in titles and abstracts')\n",
    "plt.xlabel('rank')\n",
    "plt.ylabel('total appearances');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length : 38659\n"
     ]
    }
   ],
   "source": [
    "empty = 0 # RNN mask of no data\n",
    "eos = 1  # end of sentence\n",
    "start_idx = eos+1 # first real word\n",
    "\n",
    "def get_idx(vocab, vocabcount):\n",
    "    word2idx = dict((word, idx+start_idx) for idx,word in enumerate(vocab))\n",
    "    word2idx['<empty>'] = empty\n",
    "    word2idx['<eos>'] = eos\n",
    "    \n",
    "    idx2word = dict((idx,word) for word,idx in word2idx.items())\n",
    "\n",
    "    return word2idx, idx2word\n",
    "\n",
    "word2idx, idx2word = get_idx(vocab, vocabcount)\n",
    "print('Vocabulary length :', len(word2idx))\n",
    "vocab_size = len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/glove.6B.100d.txt\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 100\n",
    "fname = 'glove.6B.%dd.txt'%embedding_dim\n",
    "import os\n",
    "datadir_base = '../'\n",
    "datadir = os.path.join(datadir_base, 'data')\n",
    "glove_name = os.path.join(datadir, fname)\n",
    "print(glove_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_index_dict = {}\n",
    "glove_embedding_weights = np.empty((400000, embedding_dim))\n",
    "global_scale=.1\n",
    "with open(glove_name, 'r',encoding=\"utf8\") as fp:\n",
    "    i = 0\n",
    "    for l in fp:\n",
    "        l = l.strip().split()\n",
    "        w = l[0]\n",
    "        glove_index_dict[w] = i        \n",
    "        glove_embedding_weights[i,:] = [float(x) for x in l[1:]]\n",
    "        i += 1\n",
    "glove_embedding_weights *= global_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w,i in glove_index_dict.items():\n",
    "    w = w.lower()\n",
    "    if w not in glove_index_dict:\n",
    "        glove_index_dict[w] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random-embedding/glove scale 0.0706949139514209 std 0.04081470228670095\n",
      "number of tokens, in small vocab, found in glove and copied to embedding 12717 0.32895315450477247\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "shape = (vocab_size, embedding_dim)\n",
    "scale = glove_embedding_weights.std()*np.sqrt(12)/2 # uniform and not normal\n",
    "embedding = np.random.uniform(low=-scale, high=scale, size=shape)\n",
    "print('random-embedding/glove scale', scale, 'std', embedding.std())\n",
    "\n",
    "# copy from glove weights of words that appear in our short vocabulary (idx2word)\n",
    "c = 0\n",
    "for i in range(vocab_size):\n",
    "    w = idx2word[i]\n",
    "    g = glove_index_dict.get(w, glove_index_dict.get(w.lower()))\n",
    "    if g is None and w.startswith('#'): # glove has no hastags (I think...)\n",
    "        w = w[1:]\n",
    "        g = glove_index_dict.get(w, glove_index_dict.get(w.lower()))\n",
    "    if g is not None:\n",
    "        embedding[i,:] = glove_embedding_weights[g,:]\n",
    "        c+=1\n",
    "print('number of tokens, in small vocab, found in glove and copied to embedding', c,c/float(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_thr = 0.5\n",
    "\n",
    "word2glove = {}\n",
    "for w in word2idx:\n",
    "    if w in glove_index_dict:\n",
    "        g = w\n",
    "    elif w.lower() in glove_index_dict:\n",
    "        g = w.lower()\n",
    "    elif w.startswith('#') and w[1:] in glove_index_dict:\n",
    "        g = w[1:]\n",
    "    elif w.startswith('#') and w[1:].lower() in glove_index_dict:\n",
    "        g = w[1:].lower()\n",
    "    else:\n",
    "        continue\n",
    "    word2glove[w] = g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of glove substitutes found 12\n"
     ]
    }
   ],
   "source": [
    "normed_embedding = embedding/np.array([np.sqrt(np.dot(gweight,gweight)) for gweight in embedding])[:,None]\n",
    "\n",
    "nb_unknown_words = 100\n",
    "\n",
    "glove_match = []\n",
    "for w,idx in word2idx.items():    \n",
    "    if idx >= vocab_size-nb_unknown_words and w.isalpha() and w in word2glove:        \n",
    "        gidx = glove_index_dict[word2glove[w]]\n",
    "        gweight = glove_embedding_weights[gidx,:].copy()\n",
    "        # find row in embedding that has the highest cos score with gweight\n",
    "        gweight /= np.sqrt(np.dot(gweight,gweight))\n",
    "        score = np.dot(normed_embedding[:vocab_size-nb_unknown_words], gweight)\n",
    "        while True:\n",
    "            embedding_idx = score.argmax()\n",
    "            s = score[embedding_idx]\n",
    "            if s < glove_thr:\n",
    "                break\n",
    "            if idx2word[embedding_idx] in word2glove :\n",
    "                glove_match.append((w, embedding_idx, s)) \n",
    "                break\n",
    "            score[embedding_idx] = -1\n",
    "glove_match.sort(key = lambda x: -x[2])\n",
    "print('# of glove substitutes found', len(glove_match))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.876881126468972 helping => help\n",
      "0.8451216562201643 buildings => building\n",
      "0.7805469306151109 inaccuracies => inconsistencies\n",
      "0.7456739371234078 richard => j.\n",
      "0.7280355244514656 iron => metal\n",
      "0.662634700972244 stem => cells\n",
      "0.6553164470513101 sejnowski => hovland\n",
      "0.6463356619773969 incrementing => randomizing\n",
      "0.5650256863150407 qualia => schemata\n",
      "0.5453632270853437 equipments => machinery\n",
      "0.5391948958328436 stratum => layer\n",
      "0.5207077463433016 polysilicon => multilayer\n"
     ]
    }
   ],
   "source": [
    "for orig, sub, score in glove_match:\n",
    "    print(score, orig,'=>', idx2word[sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4659\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Length of Sentences in titles')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "glove_idx2idx = dict((word2idx[w],embedding_idx) for  w, embedding_idx, _ in glove_match)\n",
    "Y = [[word2idx[token] for token in title.split()] for title in titles]\n",
    "print(len(Y))\n",
    "plt.hist([len(p) for p in Y],bins=50);\n",
    "plt.xlabel('Length of Sentences in titles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Length of Sentences in abstracts')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = [[word2idx[token] for token in a.split()] for a in abstracts]\n",
    "len(X)\n",
    "plt.hist([len(p) for p in X],bins=50)\n",
    "plt.xlabel('Length of Sentences in abstracts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_path = '../data'\n",
    "FN = 'embeddings.pkl'\n",
    "with open(os.path.join(pickle_path,FN),'wb') as fp:\n",
    "    pickle.dump((embedding, idx2word, word2idx, glove_idx2idx),fp,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "FN = 'data.pkl'\n",
    "with open(os.path.join(pickle_path,FN),'wb') as fp:\n",
    "    pickle.dump((X,Y),fp,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18, 75, 34, 3, 2474, 1076, 2861, 10, 66, 1385, 13, 213, 6, 1162, 17650, 802, 2, 66, 2861, 21, 5217, 138, 160, 13, 152, 2628, 7, 2, 121, 3346, 773, 3, 17651, 18, 26, 3, 4250, 10, 2375, 23, 18, 2671, 3, 6032, 30, 1058, 4, 41, 2224, 3, 31, 668, 7, 2, 1349, 3346, 9805, 18, 1562, 6, 2101, 4504, 193, 5, 11, 6, 18, 3093, 2662, 1162, 174, 17, 7359] [4250, 3, 1076, 1671, 5, 67, 213]\n",
      "Sentence :  ['an', 'efficient', 'method', 'of', 'self-organizing', 'associative', 'databases', 'is', 'proposed', 'together', 'with', 'applications', 'to', 'robot', 'eyesight', 'systems.', 'the', 'proposed', 'databases', 'can', 'associate', 'any', 'input', 'with', 'some', 'output.', 'in', 'the', 'first', 'half', 'part', 'of', 'discussion,', 'an', 'algorithm', 'of', 'self-organization', 'is', 'proposed.', 'from', 'an', 'aspect', 'of', 'hardware,', 'it', 'produces', 'a', 'new', 'style', 'of', 'neural', 'network.', 'in', 'the', 'latter', 'half', 'part,', 'an', 'applicability', 'to', 'handwritten', 'letter', 'recognition', 'and', 'that', 'to', 'an', 'autonomous', 'mobile', 'robot', 'system', 'are', 'demonstrated.']\n",
      "Summary :  ['self-organization', 'of', 'associative', 'database', 'and', 'its', 'applications']\n"
     ]
    }
   ],
   "source": [
    "print(X[0],Y[0])\n",
    "print(\"Sentence : \",  [idx2word[p] for p in X[0]])\n",
    "print(\"Summary : \", [idx2word[p] for p in Y[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples:  3354\n",
      "Number of validation samples:  372\n",
      "Number of test samples:  932\n",
      "Number of training batches:  1677\n",
      "Number of validation batches:  186\n",
      "Total entries:  3726\n"
     ]
    }
   ],
   "source": [
    "p_W, p_U, p_dense, p_emb, weight_decay = 0, 0, 0, 0, 0\n",
    "LR = 1e-4\n",
    "batch_size = 2\n",
    "\n",
    "def clip_to_batch(data, batch_size):\n",
    "    data = data[0:len(data)-len(data)%batch_size]\n",
    "    return data\n",
    "\n",
    "# split data into train, validation, and test set\n",
    "trainX, testX, trainY, testY = train_test_split(X, Y, test_size= 0.2 , random_state=seed)\n",
    "trainX, valX, trainY, valY = train_test_split(trainX, trainY, test_size = 0.1 , random_state = seed)\n",
    "\n",
    "trainX = clip_to_batch(trainX, batch_size)\n",
    "trainY = clip_to_batch(trainY, batch_size)\n",
    "valX = clip_to_batch(valX, batch_size)\n",
    "valY = clip_to_batch(valY, batch_size)\n",
    "testX = clip_to_batch(testX, batch_size)\n",
    "testY = clip_to_batch(testY, batch_size)\n",
    "print('Number of training samples: ', len(trainX))\n",
    "print('Number of validation samples: ', len(valX))\n",
    "print('Number of test samples: ', len(testX))\n",
    "\n",
    "num_train_batches = len(trainX) // batch_size\n",
    "num_val_samples = len(valX)\n",
    "num_val_batches = len(valX) // batch_size\n",
    "total_entries = (num_train_batches + num_val_batches)*batch_size\n",
    "print('Number of training batches: ', num_train_batches)\n",
    "print('Number of validation batches: ', num_val_batches)\n",
    "print('Total entries: ', total_entries)\n",
    "\n",
    "#maximum length for title \n",
    "# tMaxLen = 20\n",
    "tMaxLen = 250\n",
    "#maximum length for abstract\n",
    "aMaxLen = 250\n",
    "#total maximum length\n",
    "maxlen = tMaxLen + aMaxLen\n",
    "oov0 = vocab_size-nb_unknown_words\n",
    "\n",
    "batch_norm=False\n",
    "\n",
    "nUnique = embedding.shape[0]\n",
    "hidden_units= embedding.shape[1]\n",
    "\n",
    "learning_rate = 0.002\n",
    "clip_norm = 1.0\n",
    "val_samples = 300\n",
    "regularizer = l2(weight_decay) if weight_decay else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#padding function for abstracts\n",
    "def padAbstract(x, maxL = aMaxLen, dictionary = word2idx):\n",
    "    n = len(x)\n",
    "    if n > maxL:\n",
    "        x = x[-maxL:]\n",
    "        n = maxL\n",
    "    return [dictionary['_']]*(maxL - n) + x + [dictionary['*']]\n",
    "\n",
    "#build generator for model\n",
    "def generator(trainX, trainY, batch_size = batch_size, \n",
    "              nb_batches = None, model = None, seed = seed):\n",
    "    \n",
    "    #UNDERSTAND THIS\n",
    "    c = nb_batches if nb_batches else 0\n",
    "    while True:\n",
    "        titles = list()\n",
    "        abstracts = list()\n",
    "        if nb_batches and c >= nb_batches:\n",
    "            c = 0\n",
    "        new_seed = random.randint(0, sys.maxsize)\n",
    "        random.seed(c+123456789+seed)\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            a = random.randint(0,len(trainX)-1)\n",
    "            \n",
    "            #random shuffling of data\n",
    "            abstract = trainX[a]\n",
    "            s = random.randint(min(aMaxLen,len(abstract)), max(aMaxLen,len(abstract)))\n",
    "            abstracts.append(abstract[:s])\n",
    "            \n",
    "            title = trainY[a]\n",
    "            s = random.randint(min(tMaxLen,len(title)), max(tMaxLen,len(title)))\n",
    "            titles.append(title[:s])\n",
    "\n",
    "        # undo the seeding before we yield in order not to affect the caller\n",
    "        c+= 1\n",
    "        random.seed(new_seed)\n",
    "\n",
    "        yield conv_seq_labels(abstracts, titles)\n",
    "\n",
    "#pad sequence and convert title to labels\n",
    "def conv_seq_labels(abstracts, titles, nflips = None, model = None, dictionary = word2idx):\n",
    "    \"\"\"abstract and titles are converted to padded input vectors. Titles are one-hot encoded to labels.\"\"\"\n",
    "    batch_size = len(titles)\n",
    "    \n",
    "    x = [padAbstract([a+t]) for a,t in zip(abstracts, titles)] \n",
    "    x = sequence.pad_sequences(x, maxlen = tMaxLen, value = dictionary['_'], \n",
    "                               padding = 'post', truncating = 'post')\n",
    "        \n",
    "    y = np.zeros((batch_size, tMaxLen, nUnique))\n",
    "    for i, it in enumerate(titles):\n",
    "        it = it + [dictionary['*']] + [dictionary['_']]*tMaxLen  # output does have a eos at end\n",
    "        it = it[:tMaxLen]\n",
    "        y[i,:,:] = np_utils.to_categorical(it, nUnique)\n",
    "        \n",
    "    #The 3 inputs are abstract, title starting with eos and a one-hot encoding of the title categorical variables.\n",
    "    return [x[:,:aMaxLen],x[:,aMaxLen:]], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpadd(x, maxlend=tMaxLen, eos=eos):\n",
    "    assert maxlend >= 0\n",
    "    if maxlend == 0:\n",
    "        return [eos]\n",
    "    n = len(x)\n",
    "    if n > maxlend:\n",
    "        x = x[-maxlend:]\n",
    "        n = maxlend\n",
    "    return [empty]*(maxlend-n) + x + [eos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_fold(xs):\n",
    "    xs = [x if x < oov0 else glove_idx2idx.get(x,x) for x in xs]\n",
    "    # the more popular word is <0> and so on\n",
    "    outside = sorted([x for x in xs if x >= oov0])\n",
    "    # if there are more than nb_unknown_words oov words then put them all in nb_unknown_words-1\n",
    "    outside = dict((x,vocab_size-1-min(i, nb_unknown_words-1)) for i, x in enumerate(outside))\n",
    "    xs = [outside.get(x,x) for x in xs]\n",
    "    return xs\n",
    "\n",
    "def vocab_unfold(desc,xs):\n",
    "    # assume desc is the unfolded version of the start of xs\n",
    "    unfold = {}\n",
    "    for i, unfold_idx in enumerate(desc):\n",
    "        fold_idx = xs[i]\n",
    "        if fold_idx >= vocab_size-nb_unknown_words:\n",
    "            unfold[fold_idx] = unfold_idx\n",
    "    return [unfold.get(x,x) for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(Xd, Xh, batch_size=batch_size, nb_batches=None, model=None, seed=seed):\n",
    "    c = nb_batches if nb_batches else 0\n",
    "    while True:\n",
    "        xds = []\n",
    "        xhs = []\n",
    "        if nb_batches and c >= nb_batches:\n",
    "            c = 0\n",
    "        new_seed = random.randint(0, sys.maxsize)\n",
    "        random.seed(c+123456789+seed)\n",
    "        for b in range(batch_size):\n",
    "            t = random.randint(0,len(Xd)-1)\n",
    "            \n",
    "            #random shuffling of data\n",
    "            xd = Xd[t]\n",
    "            s = random.randint(min(aMaxLen,len(xd)), max(aMaxLen,len(xd)))\n",
    "            xds.append(xd[:s])\n",
    "            \n",
    "            xh = Xh[t]\n",
    "            s = random.randint(min(tMaxLen,len(xh)), max(tMaxLen,len(xh)))\n",
    "            xhs.append(xh[:s])\n",
    "\n",
    "        # undo the seeding before we yield inorder not to affect the caller\n",
    "        c+= 1\n",
    "        random.seed(new_seed)\n",
    "\n",
    "        yield conv_seq_labels(xds, xhs)\n",
    "\n",
    "def conv_seq_labels(xds, xhs, nflips=None, model=None):\n",
    "    \"\"\"description and hedlines are converted to padded input vectors. headlines are one-hot to label\"\"\"\n",
    "    batch_size = len(xhs)\n",
    "    \n",
    "    x = [vocab_fold(lpadd(xd)+xh) for xd,xh in zip(xds,xhs)]  # the input does not have 2nd eos\n",
    "    x = sequence.pad_sequences(x, maxlen=maxlen, value= word2idx['_'], padding='post', truncating='post')\n",
    "        \n",
    "    y = np.zeros((batch_size, tMaxLen, vocab_size))\n",
    "    for i, xh in enumerate(xhs):\n",
    "        xh = vocab_fold(xh) + [eos] + [empty]*tMaxLen  # output does have a eos at end\n",
    "        xh = xh[:tMaxLen]\n",
    "        y[i,:,:] = np_utils.to_categorical(xh, vocab_size)\n",
    "        \n",
    "    #The 3 inputs are description, summary starting with eos and a one-hot encoding of the summary categoricals\n",
    "    return [x[:,:aMaxLen],x[:,tMaxLen:]], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 250) (2, 250) (2, 250, 38659)\n",
      "Description  :  ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', 'we', 'consider', 'the', 'problem', 'of', 'estimating', 'neural', 'spikes', 'from', 'extracellular', 'voltage', 'recordings.', 'most', 'current', 'methods', 'are', 'based', 'on', 'clustering,', 'which', 'requires', 'substantial', 'human', 'supervision', 'and', 'produces', 'systematic', 'errors', 'by', 'failing', 'to', 'properly', 'handle', 'temporally', 'overlapping', 'spikes.', 'we', 'formulate', 'the', 'problem', 'as', 'one', 'of', 'statistical', 'inference,', 'in', 'which', 'the', 'recorded', 'voltage', 'is', 'a', 'noisy', 'sum', 'of', 'the', 'spike', 'trains', 'of', 'each', 'neuron', 'convolved', 'with', 'its', 'associated', 'spike', 'waveform.', 'joint', 'maximum-a-posteriori', '(map)', 'estimation', 'of', 'the', 'waveforms', 'and', 'spikes', 'is', 'then', 'a', 'blind', 'deconvolution', 'problem', 'in', 'which', 'the', 'coefficients', 'are', 'sparse.', 'we', 'develop', 'a', 'block-coordinate', 'descent', 'method', 'for', 'approximating', 'the', 'map', 'solution.', 'we', 'validate', 'our', 'method', 'on', 'data', 'simulated', 'according', 'to', 'the', 'generative', 'model,', 'as', 'well', 'as', 'on', 'real', 'data', 'for', 'which', 'ground', 'truth', 'is', 'available', 'via', 'simultaneous', 'intracellular', 'recordings.', 'in', 'both', 'cases,', 'our', 'method', 'substantially', 'reduces', 'the', 'number', 'of', 'missed', 'spikes', 'and', 'false', 'positives', 'when', 'compared', 'to', 'a', 'standard', 'clustering', 'algorithm,', 'primarily', 'by', 'recovering', 'temporally', 'overlapping', 'spikes.', 'the', 'method', 'offers', 'a', 'fully', 'automated', 'alternative', 'to', 'clustering', 'methods', 'that', 'is', 'less', 'susceptible', 'to', 'systematic', 'errors.']\n",
      "Summary  :  ['<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', '<empty>', 'many', 'fundamental', 'questions', 'in', 'theoretical', 'neuroscience', 'involve', 'optimal', 'decoding', 'and', 'the', 'computation', 'of', 'shannon', 'information', 'rates', 'in', 'populations', 'of', 'spiking', 'neurons.', 'in', 'this', 'paper,', 'we', 'apply', 'methods', 'from', 'the', 'asymptotic', 'theory', 'of', 'statistical', 'inference', 'to', 'obtain', 'a', 'clearer', 'analytical', 'understanding', 'of', 'these', 'quantities.', 'we', 'find', 'that', 'for', 'large', 'neural', 'populations', 'carrying', 'a', 'finite', 'total', 'amount', 'of', 'information,', 'the', 'full', 'spiking', 'population', 'response', 'is', 'asymptotically', 'as', 'informative', 'as', 'a', 'single', 'observation', 'from', 'a', 'gaussian', 'process', 'whose', 'mean', 'and', 'covariance', 'can', 'be', 'characterized', 'explicitly', 'in', 'terms', 'of', 'network', 'and', 'single', 'neuron', 'properties.', 'the', 'gaussian', 'form', 'of', 'this', 'asymptotic', 'sufficient', 'statistic', 'allows', 'us', 'in', 'certain', 'cases', 'to', 'perform', 'optimal', 'bayesian', 'decoding', 'by', 'simple', 'linear', 'transformations,', 'and', 'to', 'obtain', 'closed-form', 'expressions', 'of', 'the', 'shannon', 'information', 'carried', 'by', 'the', 'network.', 'one', 'technical', 'advantage', 'of', 'the', 'theory', 'is', 'that', 'it', 'may', 'be', 'applied', 'easily', 'even', 'to', 'non-poisson', 'point', 'process', 'network', 'models;', 'for', 'example,', 'we', 'find', 'that', 'under', 'some', 'conditions,', 'neural', 'populations', 'with', 'strong', 'history-dependent', '(non-poisson)', 'effects', 'carry', 'exactly', 'the', 'same', 'information', 'as', 'do', 'simpler', 'equivalent', 'populations', 'of', 'non-interacting', 'poisson', 'neurons', 'with', 'matched', 'firing', 'rates.', 'we', 'argue', 'that', 'our', 'findings', 'help', 'to', 'clarify', 'some', 'results', 'from', 'the', 'recent', 'literature', 'on', 'neural', 'decoding', 'and', 'neuroprosthetic', 'design.']\n"
     ]
    }
   ],
   "source": [
    "#check generator\n",
    "r = next(gen(trainX, trainY, batch_size=batch_size))\n",
    "print(r[0][0].shape,r[0][1].shape,r[1].shape)\n",
    "print(\"Description  : \", [idx2word[k] for k in r[0][0][0]])\n",
    "print(\"Summary  : \", [idx2word[k] for k in r[0][0][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator for training and validation\n",
    "genTrain = gen(trainX, trainY, batch_size = batch_size)\n",
    "genVal =  gen(valX, valY, nb_batches = len(valX)// batch_size, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder\n",
    "def getModel(genTrain, genVal, embeddMatrix=embedding, learning_rate=learning_rate, \n",
    "             clip_norm=clip_norm, encoder_shape = aMaxLen, decoder_shape = tMaxLen, \n",
    "             nUnique = vocab_size, embeddDim = embedding_dim, hidden_units = hidden_units):\n",
    "    \n",
    "    #ENCODER\n",
    "    #input shape as the vector of sequence, with length padded to 250\n",
    "    encoder_inputs = Input(shape = (encoder_shape, ), name = 'encoder_input')\n",
    "    \n",
    "    encoder_embedding = Embedding(nUnique, embeddDim, \n",
    "                                  input_length = encoder_shape, \n",
    "                                  weights = [embeddMatrix],\n",
    "                                  mask_zero = True,\n",
    "                                  name = 'encoder_embedd')(encoder_inputs)\n",
    "    \n",
    "    encoder_lstm = Bidirectional(LSTM(hidden_units, dropout = 0.2, recurrent_dropout=0.2, return_state=True))\n",
    "    \n",
    "    encoder_outputs, f_h, f_c, b_h, b_c = encoder_lstm(encoder_embedding)\n",
    "    \n",
    "    state_hfinal=Add()([f_h, b_h])\n",
    "    state_cfinal=Add()([f_c, b_c])\n",
    "    \n",
    "    encoder_states = [state_hfinal,state_cfinal]\n",
    "        \n",
    "    #DECODER\n",
    "    decoder_inputs = Input(shape = (decoder_shape, ), name = 'decoder_input')\n",
    "    \n",
    "    decoder_embedding = Embedding(nUnique, embeddDim, \n",
    "                                  input_length = decoder_shape, \n",
    "                                  weights = [embeddMatrix],\n",
    "                                  mask_zero = True,\n",
    "                                  name = 'decoder_embedd')\n",
    "    \n",
    "    decoder_lstm = LSTM(hidden_units, return_sequences = True, return_state=True)\n",
    "    \n",
    "    decoder_outputs, s_h, s_c = decoder_lstm(decoder_embedding(decoder_inputs), initial_state = encoder_states)    \n",
    "    decoder_dense = Dense(decoder_shape, activation='linear')\n",
    "    decoder_time_distributed = TimeDistributed(Dense(nUnique,\n",
    "                                                     name = 'decoder_timedistributed'))\n",
    "    decoder_activation = Activation('softmax', name = 'decoder_activation')\n",
    "    decoder_outputs = decoder_activation(decoder_time_distributed(decoder_outputs))\n",
    "    \n",
    "    #MODEL\n",
    "    model = Model(inputs = [encoder_inputs,decoder_inputs], outputs = decoder_outputs) \n",
    "    rmsprop = RMSprop(lr = learning_rate, clipnorm = clip_norm)\n",
    "    model.compile(loss = 'categorical_crossentropy',optimizer = rmsprop)\n",
    "    \n",
    "    #ENCODER MODEL\n",
    "    encoder_model = Model(encoder_inputs,encoder_states)\n",
    "    \n",
    "    #DECODER MODEL\n",
    "    decoder_state_inputs_h = Input(shape=(hidden_units,))\n",
    "    decoder_state_inputs_c = Input(shape=(hidden_units,)) \n",
    "    decoder_state_inputs = [decoder_state_inputs_h, decoder_state_inputs_c]\n",
    "    decoder_outputs, decoder_state_h, decoder_state_c = decoder_lstm(decoder_embedding(decoder_inputs),\n",
    "                                                                     initial_state = decoder_state_inputs)\n",
    "    decoder_states = [decoder_state_h, decoder_state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    decoder_model = Model([decoder_inputs] + decoder_state_inputs,\n",
    "                          [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModels(models,names):\n",
    "    path = '../models'\n",
    "    for i in range(len(names)):\n",
    "        models[i].save(os.path.join(path,names[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "model, encoder, decoder = getModel(genTrain,genVal)\n",
    "# saveModels([model,encoder,decoder],['att_model','att_encoder','att_decoder'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 250)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_embedd (Embedding)      (None, 250, 100)     3865900     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      (None, 250)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, 200), (None, 160800      encoder_embedd[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_embedd (Embedding)      (None, 250, 100)     3865900     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 100)          0           bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 100)          0           bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 250, 100), ( 80400       decoder_embedd[0][0]             \n",
      "                                                                 add_1[0][0]                      \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 250, 38659)   3904559     lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder_activation (Activation) (None, 250, 38659)   0           time_distributed_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 11,877,559\n",
      "Trainable params: 11,877,559\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit_generator(genTrain, steps_per_epoch = 100, epochs=5, validation_data = genVal,validation_steps = 20)\n",
    "# save_weights('../weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(folder):\n",
    "    model.load_weights(folder + '/model.w')\n",
    "    encoder.load_weights(folder + '/encoder.w')\n",
    "    decoder.load_weights(folder + '/decoder.w')\n",
    "    \n",
    "def save_weights(folder):\n",
    "    if not os.path.isdir(folder):\n",
    "        os.mkdir(folder)\n",
    "    model.save_weights(folder + '/model.w')\n",
    "    encoder.save_weights(folder + '/encoder.w')\n",
    "    decoder.save_weights(folder + '/decoder.w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weights('../weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(model, seq, maxLen, num_iteration, idx2word):\n",
    "    '''\n",
    "    Prediction for a given sequence. \n",
    "    \n",
    "    Parameters:\n",
    "    ===========\n",
    "    1)model: rnn model\n",
    "    2)seq: a single abstract, should be a vector of length 250\n",
    "    3)maxLen: maximum length of predicted title\n",
    "    4)idx2word: dictionary for index to word\n",
    "    '''\n",
    "    \n",
    "    #cache list of prediction\n",
    "    prediction = list()\n",
    "    #initiate title to be a vector of zeros\n",
    "    init = np.zeros(maxLen)\n",
    "    \n",
    "    #for maximum prediction length\n",
    "    for i in range(num_iteration):\n",
    "        #get prediction probabilities for all unique words\n",
    "        predRNN = model.predict([np.reshape(seq, (1, 250)), init.reshape(1, 250)])\n",
    "        #greedy mode prediction\n",
    "        #update next title vector to be the predicted vector\n",
    "        init = np.argmax(predRNN, axis = 2)\n",
    "        #get probabilities of all unique words\n",
    "        pVec = predRNN[0, 0, :]\n",
    "        #get the word with maximum predicted probability as the predicted words\n",
    "        idx = np.argmax(pVec)\n",
    "        #index to word\n",
    "        word = idx2word[idx]\n",
    "        #if eos tag is predicted\n",
    "        #break out of loop\n",
    "        if idx == 1:\n",
    "            break\n",
    "        prediction.append(word)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['universal', 'consistency', 'of', 'multi-class', 'support', 'vector', 'classification']\n",
      "['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'steinwart', 'was', 'the', '?rst', 'to', 'prove', 'universal', 'consistency', 'of', 'support', 'vector', 'machine', 'classi?cation.', 'his', 'proof', 'analyzed', 'the', '?standard?', 'support', 'vector', 'machine', 'classi?er,', 'which', 'is', 'restricted', 'to', 'binary', 'classi?cation', 'problems.', 'in', 'contrast,', 'recent', 'analysis', 'has', 'resulted', 'in', 'the', 'common', 'belief', 'that', 'several', 'extensions', 'of', 'svm', 'classi?cation', 'to', 'more', 'than', 'two', 'classes', 'are', 'inconsistent.', 'countering', 'this', 'belief,', 'we', 'proof', 'the', 'universal', 'consistency', 'of', 'the', 'multi-class', 'support', 'vector', 'machine', 'by', 'crammer', 'and', 'singer.', 'our', 'proof', 'extends', 'steinwart?s', 'techniques', 'to', 'the', 'multi-class', 'case.']\n",
      "['for', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a', 'a']\n"
     ]
    }
   ],
   "source": [
    "#check prediction \n",
    "check = testX.copy()\n",
    "check = sequence.pad_sequences(check, 250, value = word2idx['_'], padding = 'pre')\n",
    "\n",
    "ind=0\n",
    "print([idx2word[m] for m in testY[ind]])\n",
    "print([idx2word[m] for m in check[ind]])\n",
    "check_pred = getPredictions(model, check[ind], 250, 20, idx2word)\n",
    "print(check_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beam Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_rnn_predict(samples, empty=empty, model=model, maxlen=maxlen):\n",
    "    \"\"\"for every sample, calculate probability for every possible label\n",
    "    you need to supply your RNN model and maxlen - the length of sequences it can handle\n",
    "    \"\"\"\n",
    "    sample_lengths = map(len, samples)\n",
    "    assert all(l > aMaxLen for l in sample_lengths)\n",
    "    assert all(l[aMaxLen] == eos for l in samples)\n",
    "    # pad from right (post) so the first maxlend will be description followed by headline\n",
    "    data = sequence.pad_sequences(samples, maxlen=maxlen, value=empty, padding='post', truncating='post')\n",
    "    data1 = data[0][0:250]\n",
    "    data2 = data[0][250:]\n",
    "    probs = model.predict([np.reshape(data1, (1, 250)), data2.reshape(1, 250)])[0][0]\n",
    "    softmax = [output2probs(prob[sample_length-maxlend-1]) for prob, sample_length in zip(probs, sample_lengths)]\n",
    "    softmax = probs.reshape(1,-1)\n",
    "    return np.array(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beamsearch(predict, start=[empty]*aMaxLen + [eos], avoid=None, avoid_score=1,\n",
    "               k=1, maxsample=maxlen, use_unk=True, oov=vocab_size-1, empty=empty, eos=eos, temperature=1.0):\n",
    "    \"\"\"return k samples (beams) and their NLL scores, each sample is a sequence of labels,\n",
    "    all samples starts with an `empty` label and end with `eos` or truncated to length of `maxsample`.\n",
    "    You need to supply `predict` which returns the label probability of each sample.\n",
    "    `use_unk` allow usage of `oov` (out-of-vocabulary) label in samples\n",
    "    \"\"\"\n",
    "    def sample(energy, n, temperature=temperature):\n",
    "        \"\"\"sample at most n different elements according to their energy\"\"\"\n",
    "        n = min(n,len(energy))\n",
    "        prb = np.exp(-np.array(energy) / temperature )\n",
    "        res = []\n",
    "        for i in range(n):\n",
    "            z = np.sum(prb)\n",
    "            r = np.argmax(np.random.multinomial(1, prb/z, 1))\n",
    "            res.append(r)\n",
    "            prb[r] = 0. # make sure we select each element only once\n",
    "        return res\n",
    "\n",
    "    dead_samples = []\n",
    "    dead_scores = []\n",
    "    live_samples = [list(start)]\n",
    "    live_scores = [0]\n",
    "    counter = 1\n",
    "    \n",
    "    while live_samples:\n",
    "        # for every possible live sample calc prob for every possible label \n",
    "        probs = predict(live_samples, empty=empty)\n",
    "        assert vocab_size == probs.shape[1]\n",
    "\n",
    "        # total score for every sample is sum of -log of word prb\n",
    "        cand_scores = np.array(live_scores)[:,None] - np.log(probs)\n",
    "        cand_scores[:,empty] = 1e20\n",
    "        if not use_unk and oov is not None:\n",
    "            cand_scores[:,oov] = 1e20\n",
    "        if avoid:\n",
    "            for a in avoid:\n",
    "                for i, s in enumerate(live_samples):\n",
    "                    n = len(s) - len(start)\n",
    "                    if n < len(a):\n",
    "                        # at this point live_sample is before the new word,\n",
    "                        # which should be avoided, is added\n",
    "                        cand_scores[i,a[n]] += avoid_score\n",
    "        live_scores = list(cand_scores.flatten())\n",
    "\n",
    "        # find the best (lowest) scores we have from all possible dead samples and\n",
    "        # all live samples and all possible new words added\n",
    "        scores = dead_scores + live_scores\n",
    "        ranks = sample(scores, k)\n",
    "        n = len(dead_scores)\n",
    "        dead_scores = [dead_scores[r] for r in ranks if r < n]\n",
    "        dead_samples = [dead_samples[r] for r in ranks if r < n]\n",
    "        \n",
    "        live_scores = [live_scores[r-n] for r in ranks if r >= n]\n",
    "        live_samples = [live_samples[(r-n)//vocab_size]+[(r-n)%vocab_size] for r in ranks if r >= n]\n",
    "\n",
    "        # live samples that should be dead are...\n",
    "        # even if len(live_samples) == maxsample we dont want it dead because we want one\n",
    "        # last prediction out of it to reach a headline of maxlenh\n",
    "        def is_zombie(s):\n",
    "            return s[-1] == eos or len(s) > maxsample\n",
    "        \n",
    "        # add zombies to the dead\n",
    "        dead_scores += [c for s, c in zip(live_samples, live_scores) if is_zombie(s)]\n",
    "        dead_samples += [s for s in live_samples if is_zombie(s)]\n",
    "        \n",
    "        # remove zombies from the living \n",
    "        live_scores = [c for s, c in zip(live_samples, live_scores) if not is_zombie(s)]\n",
    "        live_samples = [s for s in live_samples if not is_zombie(s)]\n",
    "        counter += 1\n",
    "    \n",
    "    print(counter)\n",
    "    return dead_samples, dead_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gensamples(X=None,  avoid=None, avoid_score=1, skips=2, k=10, batch_size=batch_size, \n",
    "               short=True, temperature=1., use_unk=True):\n",
    "    if X is None or isinstance(X,int):\n",
    "        if X is None:\n",
    "            i = random.randint(0,len(testX)-1)\n",
    "        else:\n",
    "            i = X\n",
    "        print('TITLE %d:'%i,' '.join(idx2word[w] for w in testY[i]))\n",
    "        print('ABSTRACT:',' '.join(idx2word[w] for w in testX[i]))\n",
    "        x = testX[i]\n",
    "    else:\n",
    "        x = [word2idx[w.rstrip('^')] for w in X.split()]\n",
    "        \n",
    "    if avoid:\n",
    "        # avoid is a list of avoids. Each avoid is a string or list of word indicies\n",
    "        if isinstance(avoid,str) or isinstance(avoid[0], int):\n",
    "            avoid = [avoid]\n",
    "        avoid = [a.split() if isinstance(a,str) else a for a in avoid]\n",
    "        avoid = [vocab_fold([w if isinstance(w,int) else word2idx[w] for w in a])\n",
    "                 for a in avoid]\n",
    "\n",
    "    print('TITLES:')\n",
    "    samples = []\n",
    "    skips = range(min(aMaxLen,len(x)), max(aMaxLen,len(x)), abs(aMaxLen - len(x)) // skips + 1)\n",
    "    print(skips)\n",
    "    for s in skips:\n",
    "        start = lpadd(x[:s])\n",
    "        fold_start = vocab_fold(start)\n",
    "        sample, score = beamsearch(predict=keras_rnn_predict, start=fold_start, avoid=avoid, \n",
    "                                   avoid_score=avoid_score,k=k, temperature=temperature, use_unk=use_unk)\n",
    "        assert all(s[aMaxLen] == eos for s in sample)\n",
    "        samples += [(s,start,scr) for s,scr in zip(sample,score)]\n",
    "    \n",
    "    samples.sort(key=lambda x: x[-1])\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITLE 688: multi-level active prediction of useful image annotations for recognition\n",
      "ABSTRACT: we introduce a framework for actively learning visual categories from a mixture of weakly and strongly labeled image examples. we propose to allow the category-learner to strategically choose what annotations it receives---based on both the expected reduction in uncertainty as well as the relative costs of obtaining each annotation. we construct a multiple-instance discriminative classifier based on the initial training data. then all remaining unlabeled and weakly labeled examples are surveyed to actively determine which annotation ought to be requested next. after each request, the current classifier is incrementally updated. unlike previous work, our approach accounts for the fact that the optimal use of manual annotation may call for a combination of labels at multiple levels of granularity (e.g., a full segmentation on some images and a present/absent flag on others). as a result, it is possible to learn more accurate category models with a lower total expenditure of manual annotation effort.\n",
      "TITLES:\n",
      "range(152, 250, 99)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/share/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in true_divide\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n",
      "263.9286901950836 a bayesian learning the bayesian efficient learning a a order bayesian learning map efficient networks the and with nonparametric the a learning stochastic neural a a learning adaptive a learning learning in learning learning the a adaptive matrix a in with learning learning with inference a bayesian a learning with a a for for on learning a learning bayesian learning learning learning the learning a\n"
     ]
    }
   ],
   "source": [
    "samples = gensamples()\n",
    "codes = []\n",
    "short=True\n",
    "for sample, start, score in samples:\n",
    "    code = ''\n",
    "    words = []\n",
    "    sample = vocab_unfold(start, sample)[len(start):]\n",
    "    for w in sample:\n",
    "        if w == eos:\n",
    "            break\n",
    "        words.append(idx2word[w])\n",
    "        code += chr(w//(256*256)) + chr((w//256)%256) + chr(w%256)\n",
    "    if short:\n",
    "        distance = min([100] + [-Levenshtein.jaro(code,c) for c in codes])\n",
    "        if distance > -0.6:\n",
    "            print(score, ' '.join(words))\n",
    "    else:\n",
    "            print(score, ' '.join(words))\n",
    "    codes.append(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
