{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sSbQIvnPx0W0"
   },
   "source": [
    "# RNN Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "sUjoOSJCx0W2",
    "outputId": "a98b5ac6-1673-422c-c7c4-dd91d6cf17cf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import gensim as gs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import nltk\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize as wt\n",
    "from nltk.tokenize import sent_tokenize as st\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import logging\n",
    "import re\n",
    "import sys\n",
    "import random\n",
    "from collections import Counter\n",
    "from tensorflow.contrib import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Bidirectional, Dense,LSTM,Input,Activation,Add,TimeDistributed,\\\n",
    "Permute,Flatten,RepeatVector,merge,Lambda,Multiply,Reshape\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Sequential,Model\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vav79cEmx0W9"
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "histPath = ''\n",
    "#load training data\n",
    "with open(histPath+'train.txt', \"rb\") as f1, open(histPath+'val.txt', \"rb\") as f2, open(histPath+'test.txt', \"rb\") as f3: \n",
    "    trainX, trainY = pickle.load(f1)\n",
    "    valX, valY = pickle.load(f2)\n",
    "    testX, testY = pickle.load(f3)\n",
    "#load dictionaries\n",
    "with open(histPath+'word2idx_master.json', 'r') as f1, open(histPath+'idx2word_master.json', 'r') as f2:\n",
    "    word2idx = json.load(f1)\n",
    "    idx2word = json.load(f2)\n",
    "\n",
    "#load embedding matrix\n",
    "embeddMatrix = np.load(histPath+'embeddMatrix.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ADJqSYpIx0W_"
   },
   "outputs": [],
   "source": [
    "#params for model training\n",
    "seed = 209\n",
    "p_W, p_U, p_dense, p_emb, weight_decay = 0, 0, 0, 0, 0\n",
    "LR = 1e-4\n",
    "batch_size = 32\n",
    "\n",
    "num_train_batches = len(trainX) // batch_size\n",
    "num_val_samples = len(valX) + len(trainX) - batch_size*num_train_batches\n",
    "num_val_batches = len(valX) // batch_size\n",
    "total_entries = (num_train_batches + num_val_batches)*batch_size\n",
    "\n",
    "#maximum length for title \n",
    "# tMaxLen = 20\n",
    "tMaxLen = 250\n",
    "#maximum length for abstract\n",
    "aMaxLen = 250\n",
    "#total maximum length\n",
    "maxlen = tMaxLen + aMaxLen\n",
    "\n",
    "batch_norm=False\n",
    "\n",
    "embeddDim = embeddMatrix.shape[1]\n",
    "nUnique = embeddMatrix.shape[0]\n",
    "hidden_units= embeddDim\n",
    "\n",
    "learning_rate = 0.002\n",
    "clip_norm = 1.0\n",
    "# regularizer = l2(weight_decay) if weight_decay else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PjLBQTBJx0XC"
   },
   "source": [
    "---\n",
    "\n",
    "## I. Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wy8dEpxKx0XD"
   },
   "outputs": [],
   "source": [
    "#padding function for abstracts\n",
    "def padAbstract(x, maxL = aMaxLen, dictionary = word2idx):\n",
    "    n = len(x)\n",
    "    if n > maxL:\n",
    "        x = x[-maxL:]\n",
    "        n = maxL\n",
    "    return [dictionary['_']]*(maxL - n) + x + [dictionary['*']]\n",
    "\n",
    "#build generator for model\n",
    "def generator(trainX, trainY, batch_size = batch_size, \n",
    "              nb_batches = None, model = None, seed = seed):\n",
    "    \n",
    "    #UNDERSTAND THIS\n",
    "    c = nb_batches if nb_batches else 0\n",
    "    while True:\n",
    "        titles = list()\n",
    "        abstracts = list()\n",
    "        if nb_batches and c >= nb_batches:\n",
    "            c = 0\n",
    "        new_seed = random.randint(0, sys.maxsize)\n",
    "        random.seed(c+123456789+seed)\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            a = random.randint(0,len(trainX)-1)\n",
    "            \n",
    "            #random shuffling of data\n",
    "            abstract = trainX[a]\n",
    "            s = random.randint(min(aMaxLen,len(abstract)), max(aMaxLen,len(abstract)))\n",
    "            abstracts.append(abstract[:s])\n",
    "            \n",
    "            title = trainY[a]\n",
    "            s = random.randint(min(tMaxLen,len(title)), max(tMaxLen,len(title)))\n",
    "            titles.append(title[:s])\n",
    "\n",
    "        # undo the seeding before we yield in order not to affect the caller\n",
    "        c+= 1\n",
    "        random.seed(new_seed)\n",
    "\n",
    "        yield conv_seq_labels(abstracts, titles)\n",
    "\n",
    "#pad sequence and convert title to labels\n",
    "def conv_seq_labels(abstracts, titles, nflips = None, model = None, dictionary = word2idx):\n",
    "    \"\"\"abstract and titles are converted to padded input vectors. Titles are one-hot encoded to labels.\"\"\"\n",
    "    batch_size = len(titles)\n",
    "    \n",
    "    \n",
    "    x = [padAbstract(a)+t for a,t in zip(abstracts, titles)] \n",
    "    x = sequence.pad_sequences(x, maxlen = maxlen, value = dictionary['_'], \n",
    "                               padding = 'post', truncating = 'post')\n",
    "        \n",
    "    y = np.zeros((batch_size, tMaxLen, nUnique))\n",
    "    for i, it in enumerate(titles):\n",
    "        it = it + [dictionary['*']] + [dictionary['_']]*tMaxLen  # output does have a eos at end\n",
    "        it = it[:tMaxLen]\n",
    "        y[i,:,:] = np_utils.to_categorical(it, nUnique)\n",
    "        \n",
    "    #The 3 inputs are abstract, title starting with eos and a one-hot encoding of the title categorical variables.\n",
    "    return [x[:,:aMaxLen],x[:,aMaxLen:]], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "Qu8vqCWfx0XF",
    "outputId": "ea483079-9a74-4c2f-ae97-3d68efcfb768"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 250) (32, 250) (32, 250, 32471)\n",
      "Abstract  :  ['_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', 'with', 'the', 'increase', 'in', 'available', 'data', 'parallel', 'machine', 'learning', 'has', '<ign>', '<ign>', 'become', 'an', 'increasingly', 'pressing', 'problem.', 'in', 'this', 'paper', 'we', 'present', '<ign>', '<ign>', 'the', 'first', 'parallel', 'stochastic', 'gradient', 'descent', 'algorithm', 'including', 'a', '<ign>', '<ign>', 'detailed', 'analysis', 'and', 'experimental', 'evidence.', 'unlike', 'prior', 'work', 'on', '<ign>', '<ign>', 'parallel', 'optimization', 'algorithms', 'our', '<ign>', '<ign>', 'variant', 'comes', 'with', 'parallel', 'acceleration', 'guarantees', 'and', 'it', 'poses', 'no', '<ign>', '<ign>', 'overly', 'tight', 'latency', 'constraints,', 'which', 'might', 'only', 'be', 'available', 'in', '<ign>', '<ign>', 'the', 'multicore', 'setting.', 'our', 'analysis', 'introduces', 'a', 'novel', 'proof', '<ign>', '<ign>', 'technique', '<ign>', 'contractive', 'mappings', 'to', 'quantify', 'the', '<ign>', '<ign>', 'speed', 'of', 'convergence', 'of', 'parameter', 'distributions', 'to', 'their', 'asymptotic', '<ign>', '<ign>', 'limits.', 'as', 'a', 'side', 'effect', 'this', 'answers', 'the', 'question', 'of', 'how', 'quickly', '<ign>', '<ign>', 'stochastic', 'gradient', 'descent', 'algorithms', 'reach', 'the', 'asymptotically', '<ign>', '<ign>', 'normal', 'regime.']\n",
      "Title  :  ['*', 'parallelized', 'stochastic', 'gradient', 'descent', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_', '_']\n"
     ]
    }
   ],
   "source": [
    "#check generator\n",
    "check = next(generator(trainX, trainY, batch_size = batch_size))\n",
    "print(check[0][0].shape,check[0][1].shape,check[1].shape)\n",
    "print(\"Abstract  : \", [idx2word[str(i)] for i in check[0][0][1]])\n",
    "print(\"Title  : \", [idx2word[str(i)] for i in check[0][1][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LsDy6pxNx0XJ"
   },
   "outputs": [],
   "source": [
    "#generator for training and validation\n",
    "genTrain = generator(trainX, trainY, batch_size = batch_size)\n",
    "genVal =  generator(valX, valY, nb_batches = len(valX)// batch_size, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A-9jfFGRx0XM"
   },
   "source": [
    "---\n",
    "\n",
    "## II. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4FETS5-o0w4O"
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M0SuCA_hx0XN"
   },
   "outputs": [],
   "source": [
    "#encoder\n",
    "def getModel(num_epochs, genTrain, genVal, embeddMatrix, learning_rate, clip_norm,\n",
    "             encoder_shape = aMaxLen, decoder_shape = tMaxLen, \n",
    "             nUnique = nUnique, embeddDim = embeddDim, hidden_units = hidden_units):\n",
    "    \n",
    "    #ENCODER\n",
    "    #input shape as the vector of sequence, with length padded to 250\n",
    "    encoder_inputs = Input(shape = (encoder_shape, ), name = 'encoder_input')\n",
    "    \n",
    "    encoder_embedding = Embedding(nUnique, embeddDim, \n",
    "                                  input_length = encoder_shape, \n",
    "                                  weights = [embeddMatrix],\n",
    "                                  mask_zero = True,\n",
    "                                  name = 'encoder_embedd')(encoder_inputs)\n",
    "    \n",
    "    encoder_lstm = Bidirectional(LSTM(hidden_units, dropout_U = 0.2,\n",
    "                                      dropout_W = 0.2 , return_state=True))\n",
    "    \n",
    "    encoder_outputs, f_h, f_c, b_h, b_c = encoder_lstm(encoder_embedding)\n",
    "    \n",
    "    state_hfinal=Add()([f_h, b_h])\n",
    "    state_cfinal=Add()([f_c, b_c])\n",
    "    \n",
    "    encoder_states = [state_hfinal,state_cfinal]\n",
    "        \n",
    "    #DECODER\n",
    "    decoder_inputs = Input(shape = (decoder_shape, ), name = 'decoder_input')\n",
    "    \n",
    "    decoder_embedding = Embedding(nUnique, embeddDim, \n",
    "                                  input_length = decoder_shape, \n",
    "                                  weights = [embeddMatrix],\n",
    "                                  mask_zero = True,\n",
    "                                  name = 'decoder_embedd')\n",
    "    \n",
    "    decoder_lstm = LSTM(hidden_units,return_sequences = True, return_state=True)\n",
    "    \n",
    "    decoder_outputs, s_h, s_c = decoder_lstm(decoder_embedding(decoder_inputs), initial_state = encoder_states)    \n",
    "    decoder_dense = Dense(decoder_shape, activation='linear')\n",
    "    decoder_time_distributed = TimeDistributed(Dense(nUnique,\n",
    "                                                     name = 'decoder_timedistributed'))\n",
    "    decoder_activation = Activation('softmax', name = 'decoder_activation')\n",
    "    decoder_outputs = decoder_activation(decoder_time_distributed(decoder_outputs))\n",
    "    \n",
    "    #MODEL\n",
    "    model = Model(inputs = [encoder_inputs,decoder_inputs], outputs = decoder_outputs) \n",
    "    rmsprop = RMSprop(lr = learning_rate, clipnorm = clip_norm)\n",
    "    model.compile(loss = 'categorical_crossentropy',optimizer = rmsprop)\n",
    "    return model, 0, 0\n",
    "    #FIT MODEL\n",
    "#     model.fit_generator(genTrain,\n",
    "#                         steps_per_epoch = num_train_batches,\n",
    "#                         epochs=num_epochs, \n",
    "#                         validation_data = genVal,\n",
    "#                         validation_steps = num_val_batches)\n",
    "    \n",
    "#     #ENCODER MODEL\n",
    "#     encoder_model = Model(encoder_inputs,encoder_states)\n",
    "    \n",
    "#     #DECODER MODEL\n",
    "#     decoder_state_inputs_h = Input(shape=(hidden_units,))\n",
    "#     decoder_state_inputs_c = Input(shape=(hidden_units,)) \n",
    "#     decoder_state_inputs = [decoder_state_inputs_h, decoder_state_inputs_c]\n",
    "#     decoder_outputs, decoder_state_h, decoder_state_c = decoder_lstm(decoder_embedding(decoder_inputs),\n",
    "#                                                                      initial_state = decoder_state_inputs)\n",
    "#     decoder_states = [decoder_state_h, decoder_state_c]\n",
    "#     decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "#     decoder_model = Model([decoder_inputs] + decoder_state_inputs,\n",
    "#                           [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    #return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "id": "Gkx0XSiRx0XQ",
    "outputId": "a4c3bbbc-0d02-45a2-b6b6-6af17a45f58d"
   },
   "outputs": [],
   "source": [
    "rnn, encoder, decoder = getModel(15, genTrain, genVal, embeddMatrix, learning_rate, clip_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "104/104 [==============================] - 381s 4s/step - loss: 6.7924 - val_loss: 6.4424\n",
      "Epoch 2/15\n",
      "104/104 [==============================] - 365s 4s/step - loss: 6.0360 - val_loss: 6.2462\n",
      "Epoch 3/15\n",
      "104/104 [==============================] - 367s 4s/step - loss: 5.7731 - val_loss: 6.1418\n",
      "Epoch 4/15\n",
      "104/104 [==============================] - 377s 4s/step - loss: 5.5584 - val_loss: 6.0337\n",
      "Epoch 5/15\n",
      "104/104 [==============================] - 369s 4s/step - loss: 5.3389 - val_loss: 5.9530\n",
      "Epoch 6/15\n",
      "104/104 [==============================] - 375s 4s/step - loss: 5.1533 - val_loss: 5.9167\n",
      "Epoch 7/15\n",
      "104/104 [==============================] - 370s 4s/step - loss: 5.0003 - val_loss: 5.8666\n",
      "Epoch 8/15\n",
      "104/104 [==============================] - 364s 4s/step - loss: 4.8257 - val_loss: 5.8629\n",
      "Epoch 9/15\n",
      "104/104 [==============================] - 366s 4s/step - loss: 4.6572 - val_loss: 5.8545\n",
      "Epoch 10/15\n",
      "104/104 [==============================] - 374s 4s/step - loss: 4.4918 - val_loss: 5.8508\n",
      "Epoch 11/15\n",
      "104/104 [==============================] - 364s 4s/step - loss: 4.3215 - val_loss: 5.8996\n",
      "Epoch 12/15\n",
      "104/104 [==============================] - 371s 4s/step - loss: 4.2258 - val_loss: 5.9271\n",
      "Epoch 13/15\n",
      "104/104 [==============================] - 369s 4s/step - loss: 4.0888 - val_loss: 5.9581\n",
      "Epoch 14/15\n",
      "104/104 [==============================] - 370s 4s/step - loss: 3.9373 - val_loss: 6.0191\n",
      "Epoch 15/15\n",
      "104/104 [==============================] - 364s 4s/step - loss: 3.8518 - val_loss: 6.0481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcf68c63b00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.fit_generator(genTrain,\n",
    "                    steps_per_epoch = num_train_batches,\n",
    "                    epochs=15, \n",
    "                    validation_data = genVal,\n",
    "                    validation_steps = num_val_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save models\n",
    "rnn.save_weights('rnn_weights_0508.h5')\n",
    "# encoder.save('encoder.h5')\n",
    "# decoder.save('decoder.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, 250)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_embedd (Embedding)      (None, 250, 100)     3247100     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      (None, 250)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, 200), (None, 160800      encoder_embedd[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "decoder_embedd (Embedding)      (None, 250, 100)     3247100     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 100)          0           bidirectional_1[0][1]            \n",
      "                                                                 bidirectional_1[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 100)          0           bidirectional_1[0][2]            \n",
      "                                                                 bidirectional_1[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 250, 100), ( 80400       decoder_embedd[0][0]             \n",
      "                                                                 add_1[0][0]                      \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 250, 32471)   3279571     lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder_activation (Activation) (None, 250, 32471)   0           time_distributed_1[0][0]         \n",
      "==================================================================================================\n",
      "Total params: 10,014,971\n",
      "Trainable params: 10,014,971\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "rnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': '_',\n",
       " '1': '*',\n",
       " '2': '<ign>',\n",
       " '3': 'self-organization',\n",
       " '4': 'of',\n",
       " '5': 'associative',\n",
       " '6': 'database',\n",
       " '7': 'and',\n",
       " '8': 'its',\n",
       " '9': 'applications',\n",
       " '10': 'a',\n",
       " '11': 'mean',\n",
       " '12': 'field',\n",
       " '13': 'theory',\n",
       " '14': 'layer',\n",
       " '15': 'iv',\n",
       " '16': 'visual',\n",
       " '17': 'cortex',\n",
       " '18': 'application',\n",
       " '19': 'to',\n",
       " '20': 'artificial',\n",
       " '21': 'neural',\n",
       " '22': 'networks',\n",
       " '23': 'bayesian',\n",
       " '24': 'query',\n",
       " '25': 'construction',\n",
       " '26': 'for',\n",
       " '27': 'network',\n",
       " '28': 'models',\n",
       " '29': 'ensembles,',\n",
       " '30': 'cross',\n",
       " '31': 'validation,',\n",
       " '32': 'active',\n",
       " '33': 'learning',\n",
       " '34': 'using',\n",
       " '35': 'net',\n",
       " '36': 'instantiate',\n",
       " '37': 'deformable',\n",
       " '38': 'model',\n",
       " '39': 'iceg',\n",
       " '40': 'morphology',\n",
       " '41': 'classification',\n",
       " '42': 'an',\n",
       " '43': 'analogue',\n",
       " '44': 'vlsi',\n",
       " '45': 'real-time',\n",
       " '46': 'control',\n",
       " '47': 'tokamak',\n",
       " '48': 'plasma',\n",
       " '49': 'pulsestream',\n",
       " '50': 'synapses',\n",
       " '51': 'with',\n",
       " '52': 'non-volatile',\n",
       " '53': 'amorphous-silicon',\n",
       " '54': 'memories',\n",
       " '55': 'training',\n",
       " '56': 'multilayer',\n",
       " '57': 'perceptrons',\n",
       " '58': 'the',\n",
       " '59': 'extended',\n",
       " '60': 'kalman',\n",
       " '61': 'algorithm',\n",
       " '62': 'rapid',\n",
       " '63': 'graph-based',\n",
       " '64': 'method',\n",
       " '65': 'arbitrary',\n",
       " '66': 'transformation-invariant',\n",
       " '67': 'pattern',\n",
       " '68': 'connectionist',\n",
       " '69': 'speaker',\n",
       " '70': 'normalization',\n",
       " '71': 'generalized',\n",
       " '72': 'resource',\n",
       " '73': 'allocating',\n",
       " '74': 'generalization',\n",
       " '75': 'in',\n",
       " '76': 'reinforcement',\n",
       " '77': 'learning:',\n",
       " '78': 'safely',\n",
       " '79': 'approximating',\n",
       " '80': 'value',\n",
       " '81': 'function',\n",
       " '82': 'principle',\n",
       " '83': 'maximum',\n",
       " '84': 'information',\n",
       " '85': 'preservation',\n",
       " '86': 'linear',\n",
       " '87': 'systems',\n",
       " '88': 'gamma',\n",
       " '89': 'mlp',\n",
       " '90': 'speech',\n",
       " '91': 'phoneme',\n",
       " '92': 'recognition',\n",
       " '93': 'multiscale',\n",
       " '94': 'attentional',\n",
       " '95': 'framework',\n",
       " '96': 'relaxation',\n",
       " '97': 'correlated',\n",
       " '98': 'neuronal',\n",
       " '99': 'response:',\n",
       " '100': 'time',\n",
       " '101': 'scales',\n",
       " '102': 'mechanisms',\n",
       " '103': 'onset-based',\n",
       " '104': 'sound',\n",
       " '105': 'segmentation',\n",
       " '106': 'transparent',\n",
       " '107': 'motion',\n",
       " '108': 'non-transparent',\n",
       " '109': 'aftereffects',\n",
       " '110': 'remap:',\n",
       " '111': 'recursive',\n",
       " '112': 'estimation',\n",
       " '113': 'maximization',\n",
       " '114': 'posteriori',\n",
       " '115': 'probabilities',\n",
       " '116': 'transition-based',\n",
       " '117': 'practical',\n",
       " '118': 'monte',\n",
       " '119': 'carlo',\n",
       " '120': 'implementation',\n",
       " '121': 'adaptive',\n",
       " '122': 'that',\n",
       " '123': 'learns',\n",
       " '124': 'sequences',\n",
       " '125': 'transitions',\n",
       " '126': 'neuron-mos',\n",
       " '127': 'temporal',\n",
       " '128': 'winner',\n",
       " '129': 'search',\n",
       " '130': 'hardware',\n",
       " '131': 'fully-parallel',\n",
       " '132': 'data',\n",
       " '133': 'processing',\n",
       " '134': 'dynamics',\n",
       " '135': 'attention',\n",
       " '136': 'as',\n",
       " '137': 'near',\n",
       " '138': 'saddle-node',\n",
       " '139': 'bifurcation',\n",
       " '140': 'behavior',\n",
       " '141': 'quadratic-type',\n",
       " '142': 'lyapunov',\n",
       " '143': 'functions',\n",
       " '144': 'competitive',\n",
       " '145': 'different',\n",
       " '146': 'time-scales',\n",
       " '147': 'stable',\n",
       " '148': 'approximations',\n",
       " '149': 'dynamic',\n",
       " '150': 'programming',\n",
       " '151': 'stochastic',\n",
       " '152': 'problems',\n",
       " '153': 'local',\n",
       " '154': 'context-dependent',\n",
       " '155': 'classes',\n",
       " '156': 'hybrid',\n",
       " '157': 'recurrent',\n",
       " '158': 'network-hmm',\n",
       " '159': 'system',\n",
       " '160': 'digital',\n",
       " '161': 'realisation',\n",
       " '162': 'self-organising',\n",
       " '163': 'maps',\n",
       " '164': 'geometry',\n",
       " '165': 'eye',\n",
       " '166': 'rotations',\n",
       " '167': \"listing's\",\n",
       " '168': 'law',\n",
       " '169': 'by',\n",
       " '170': 'probability',\n",
       " '171': 'matching',\n",
       " '172': 'nonlinear',\n",
       " '173': 'ensembles:',\n",
       " '174': 'how',\n",
       " '175': 'overfitting',\n",
       " '176': 'can',\n",
       " '177': 'be',\n",
       " '178': 'useful',\n",
       " '179': 'seemore:',\n",
       " '180': 'view-based',\n",
       " '181': 'approach',\n",
       " '182': '3-d',\n",
       " '183': 'object',\n",
       " '184': 'multiple',\n",
       " '185': 'cues',\n",
       " '186': 'selective',\n",
       " '187': 'handwritten',\n",
       " '188': 'digit',\n",
       " '189': 'gaussian',\n",
       " '190': 'processes',\n",
       " '191': 'regression',\n",
       " '192': 'modern',\n",
       " '193': 'analytic',\n",
       " '194': 'techniques',\n",
       " '195': 'solve',\n",
       " '196': 'backpropagation',\n",
       " '197': 'signature',\n",
       " '198': 'verification',\n",
       " '199': 'family',\n",
       " '200': 'discovery',\n",
       " '201': 'structure',\n",
       " '202': 'similarity',\n",
       " '203': 'issues',\n",
       " '204': 'fourier',\n",
       " '205': 'transform',\n",
       " '206': 'constraints',\n",
       " '207': 'on',\n",
       " '208': 'modeling',\n",
       " '209': 'human',\n",
       " '210': 'parameter',\n",
       " '211': 'adaption',\n",
       " '212': 'fine',\n",
       " '213': 'markov',\n",
       " '214': 'mixtures',\n",
       " '215': 'experts',\n",
       " '216': 'unified',\n",
       " '217': 'scheme:',\n",
       " '218': 'bayesian-kullback',\n",
       " '219': 'ying-yang',\n",
       " '220': 'machine',\n",
       " '221': 'minimal',\n",
       " '222': 'weights',\n",
       " '223': 'lightness',\n",
       " '224': 'perception',\n",
       " '225': 'guides',\n",
       " '226': 'production',\n",
       " '227': 'birdsong',\n",
       " '228': 'recognizer',\n",
       " '229': 'hand-written',\n",
       " '230': 'zip',\n",
       " '231': 'code',\n",
       " '232': 'digits',\n",
       " '233': 'improving',\n",
       " '234': 'elevator',\n",
       " '235': 'performance',\n",
       " '236': 'committee',\n",
       " '237': 'diagnosis',\n",
       " '238': 'resampling',\n",
       " '239': 'sparse',\n",
       " '240': 'interactions',\n",
       " '241': \"rat's\",\n",
       " '242': 'place',\n",
       " '243': 'head',\n",
       " '244': 'direction',\n",
       " '245': 'gesture',\n",
       " '246': 'learned',\n",
       " '247': 'symplectic',\n",
       " '248': 'component',\n",
       " '249': 'analysis',\n",
       " '250': 'prediction',\n",
       " '251': 'beta',\n",
       " '252': 'sheets',\n",
       " '253': 'proteins',\n",
       " '254': 'plasticity',\n",
       " '255': 'center-surround',\n",
       " '256': 'opponent',\n",
       " '257': 'receptive',\n",
       " '258': 'fields',\n",
       " '259': 'real',\n",
       " '260': 'vision',\n",
       " '261': 'worst-case',\n",
       " '262': 'loss',\n",
       " '263': 'bounds',\n",
       " '264': 'single',\n",
       " '265': 'neurons',\n",
       " '266': 'predictive',\n",
       " '267': 'q-routing:',\n",
       " '268': 'memory-based',\n",
       " '269': 'traffic',\n",
       " '270': 'unlabeled',\n",
       " '271': 'supervised',\n",
       " '272': 'microelectronic',\n",
       " '273': 'implementations',\n",
       " '274': 'cholinergic',\n",
       " '275': 'suppression',\n",
       " '276': 'transmission',\n",
       " '277': 'may',\n",
       " '278': 'allow',\n",
       " '279': 'combined',\n",
       " '280': 'memory',\n",
       " '281': 'neocortex',\n",
       " '282': 'reading',\n",
       " '283': 'curse',\n",
       " '284': 'dimensionality',\n",
       " '285': 'analog',\n",
       " '286': 'delay',\n",
       " '287': 'vector',\n",
       " '288': 'quantization',\n",
       " '289': 'new',\n",
       " '290': 'blind',\n",
       " '291': 'signal',\n",
       " '292': 'separation',\n",
       " '293': 'classifying',\n",
       " '294': 'facial',\n",
       " '295': 'action',\n",
       " '296': 'parallel',\n",
       " '297': 'optimization',\n",
       " '298': 'controllers',\n",
       " '299': 'via',\n",
       " '300': 'policy',\n",
       " '301': 'iteration',\n",
       " '302': 'modular',\n",
       " '303': 'rbf',\n",
       " '304': 'use',\n",
       " '305': 'multi-layered',\n",
       " '306': 'coding',\n",
       " '307': 'phonetic',\n",
       " '308': 'features',\n",
       " '309': 'some',\n",
       " '310': 'results',\n",
       " '311': 'convergent',\n",
       " '312': 'unlearning',\n",
       " '313': 'em',\n",
       " '314': 'latent-variable',\n",
       " '315': 'density',\n",
       " '316': 'fitted',\n",
       " '317': 'competence',\n",
       " '318': 'acquisition',\n",
       " '319': 'autonomous',\n",
       " '320': 'mobile',\n",
       " '321': 'robot',\n",
       " '322': 'implications',\n",
       " '323': 'distributed',\n",
       " '324': 'representations',\n",
       " '325': 'explorations',\n",
       " '326': 'wave',\n",
       " '327': 'policies',\n",
       " '328': 'without',\n",
       " '329': 'measuring',\n",
       " '330': 'merits',\n",
       " '331': 'switching',\n",
       " '332': 'cerebellar',\n",
       " '333': 'movement',\n",
       " '334': 'role',\n",
       " '335': 'activity',\n",
       " '336': 'synaptic',\n",
       " '337': 'competition',\n",
       " '338': 'at',\n",
       " '339': 'neuromuscular',\n",
       " '340': 'junction',\n",
       " '341': 'early',\n",
       " '342': 'stopping',\n",
       " '343': 'heterogeneous',\n",
       " '344': 'environments',\n",
       " '345': 'primitive',\n",
       " '346': 'manipulation',\n",
       " '347': 'connectionism',\n",
       " '348': 'attention:',\n",
       " '349': 'pathway',\n",
       " '350': 'exploiting',\n",
       " '351': 'tractable',\n",
       " '352': 'substructures',\n",
       " '353': 'intractable',\n",
       " '354': 'back-propagation',\n",
       " '355': 'on-line',\n",
       " '356': 'computational',\n",
       " '357': 'power',\n",
       " '358': 'noisy',\n",
       " '359': 'spiking',\n",
       " '360': 'novel',\n",
       " '361': 'channel',\n",
       " '362': 'selection',\n",
       " '363': 'cochlear',\n",
       " '364': 'implants',\n",
       " '365': 'predict',\n",
       " '366': 'visibility',\n",
       " '367': 'invisibility',\n",
       " '368': 'from',\n",
       " '369': 'occlusion',\n",
       " '370': 'events',\n",
       " '371': 'constructive',\n",
       " '372': 'algorithms',\n",
       " '373': 'hierarchical',\n",
       " '374': 'sfmd',\n",
       " '375': 'computation',\n",
       " '376': 'methods',\n",
       " '377': 'difference',\n",
       " '378': 'continuous',\n",
       " '379': 'space',\n",
       " '380': 'microscopic',\n",
       " '381': 'equations',\n",
       " '382': 'rough',\n",
       " '383': 'energy',\n",
       " '384': 'landscape',\n",
       " '385': 'architectural',\n",
       " '386': 'mechanism',\n",
       " '387': 'direction-tuned',\n",
       " '388': 'cortical',\n",
       " '389': 'simple',\n",
       " '390': 'cells:',\n",
       " '391': 'mutual',\n",
       " '392': 'inhibition',\n",
       " '393': 'balancing',\n",
       " '394': 'between',\n",
       " '395': 'bagging',\n",
       " '396': 'bumping',\n",
       " '397': 'second-order',\n",
       " '398': 'squared',\n",
       " '399': 'penalty',\n",
       " '400': 'term',\n",
       " '401': 'skeletonization:',\n",
       " '402': 'technique',\n",
       " '403': 'trimming',\n",
       " '404': 'fat',\n",
       " '405': 'relevance',\n",
       " '406': 'assessment',\n",
       " '407': 'source',\n",
       " '408': 'faithful',\n",
       " '409': 'equivariant',\n",
       " '410': 'som',\n",
       " '411': 'hebb',\n",
       " '412': 'based',\n",
       " '413': 'their',\n",
       " '414': 'content',\n",
       " '415': 'chemotaxis',\n",
       " '416': 'nematode',\n",
       " '417': 'caenorhabditis',\n",
       " '418': 'elegans',\n",
       " '419': 'circuitry',\n",
       " '420': 'orientation',\n",
       " '421': 'tuning',\n",
       " '422': 'combining',\n",
       " '423': 'estimates',\n",
       " '424': 'regularized',\n",
       " '425': 'dual',\n",
       " '426': 'filtering',\n",
       " '427': 'prediction,',\n",
       " '428': 'smoothing',\n",
       " '429': 'valid',\n",
       " '430': 'size',\n",
       " '431': 'is',\n",
       " '432': 'more',\n",
       " '433': 'important',\n",
       " '434': 'than',\n",
       " '435': 'complex-cell',\n",
       " '436': 'responses',\n",
       " '437': 'derived',\n",
       " '438': 'inputs:',\n",
       " '439': 'surprising',\n",
       " '440': 'intradendritic',\n",
       " '441': 'solution',\n",
       " '442': 'aperture',\n",
       " '443': 'problem',\n",
       " '444': 'rule',\n",
       " '445': 'belief',\n",
       " '446': 'estimators',\n",
       " '447': 'integration:',\n",
       " '448': 'disparity',\n",
       " '449': 'lstm',\n",
       " '450': 'hard',\n",
       " '451': 'long',\n",
       " '452': 'lag',\n",
       " '453': 'gemini:',\n",
       " '454': 'gradient',\n",
       " '455': 'through',\n",
       " '456': 'matrix',\n",
       " '457': 'inversion',\n",
       " '458': 'after',\n",
       " '459': 'noise',\n",
       " '460': 'injection',\n",
       " '461': 'extraction',\n",
       " '462': 'electrosensory',\n",
       " '463': 'weakly',\n",
       " '464': 'electric',\n",
       " '465': 'fish',\n",
       " '466': 'efficient',\n",
       " '467': 'actor-tutor',\n",
       " '468': 'architecture',\n",
       " '469': 'bandit',\n",
       " '470': 'approximation',\n",
       " '471': 'optimal',\n",
       " '472': 'delayed',\n",
       " '473': 'convolved',\n",
       " '474': 'sources',\n",
       " '475': 'networks:',\n",
       " '476': 'one',\n",
       " '477': 'or',\n",
       " '478': 'two',\n",
       " '479': 'hidden',\n",
       " '480': 'layers?',\n",
       " '481': 'ocular',\n",
       " '482': 'dominance',\n",
       " '483': 'column',\n",
       " '484': 'formation:',\n",
       " '485': 'analytical',\n",
       " '486': 'predicting',\n",
       " '487': 'lifetimes',\n",
       " '488': 'dynamically',\n",
       " '489': 'allocated',\n",
       " '490': 'sequential',\n",
       " '491': 'tracking',\n",
       " '492': 'pricing',\n",
       " '493': 'financial',\n",
       " '494': 'options',\n",
       " '495': 'approaches',\n",
       " '496': '3-node',\n",
       " '497': 'np-complete',\n",
       " '498': 'accuracy',\n",
       " '499': 'speed',\n",
       " '500': 'support',\n",
       " '501': 'machines',\n",
       " '502': 'effect',\n",
       " '503': 'input',\n",
       " '504': 'dynamcis',\n",
       " '505': 'universal',\n",
       " '506': 'approximator',\n",
       " '507': 'temporally',\n",
       " '508': 'persistent',\n",
       " '509': 'bayes',\n",
       " '510': 'large',\n",
       " '511': 'feed-forward',\n",
       " '512': 'temporal-diffference',\n",
       " '513': 'annealing',\n",
       " '514': 'online',\n",
       " '515': 'finite',\n",
       " '516': 'sets:',\n",
       " '517': 'case',\n",
       " '518': 'study',\n",
       " '519': 'adaptively',\n",
       " '520': 'growing',\n",
       " '521': 'electronic',\n",
       " '522': 'receptors',\n",
       " '523': 'tactile/haptic',\n",
       " '524': 'sensing',\n",
       " '525': 'ensemble',\n",
       " '526': 'adaptable',\n",
       " '527': 'cmos',\n",
       " '528': 'winner-take-all',\n",
       " '529': 'error',\n",
       " '530': 'curves',\n",
       " '531': 'minimizing',\n",
       " '532': 'statistical',\n",
       " '533': 'bias',\n",
       " '534': 'queries',\n",
       " '535': 'condensation',\n",
       " '536': 'conditional',\n",
       " '537': 'propagation',\n",
       " '538': 'scaling',\n",
       " '539': 'speechreading:',\n",
       " '540': 'systematic',\n",
       " '541': 'comparison',\n",
       " '542': '3d',\n",
       " '543': 'recognition:',\n",
       " '544': 'view-tuned',\n",
       " '545': 'approximate',\n",
       " '546': 'solutions',\n",
       " '547': \"kanerva's\",\n",
       " '548': 'reconstructing',\n",
       " '549': 'stimulus',\n",
       " '550': 'velocity',\n",
       " '551': 'area',\n",
       " '552': 'mt',\n",
       " '553': 'improvement',\n",
       " '554': 'monte-carlo',\n",
       " '555': 'exact',\n",
       " '556': 'confidence',\n",
       " '557': 'intervals',\n",
       " '558': 'have',\n",
       " '559': 'sigmoidal',\n",
       " '560': 'salient',\n",
       " '561': 'contour',\n",
       " '562': 'binding',\n",
       " '563': 'cortically-based',\n",
       " '564': 'regularizers',\n",
       " '565': 'projective',\n",
       " '566': 'basis',\n",
       " '567': 'one-unit',\n",
       " '568': 'rules',\n",
       " '569': 'independent',\n",
       " '570': 'identification',\n",
       " '571': 'particle',\n",
       " '572': 'detectors',\n",
       " '573': 'spike',\n",
       " '574': 'neuron',\n",
       " '575': 'estimating',\n",
       " '576': 'equivalent',\n",
       " '577': 'kernels',\n",
       " '578': 'perturbation',\n",
       " '579': 'artex:',\n",
       " '580': 'self-organizing',\n",
       " '581': 'image',\n",
       " '582': 'regions',\n",
       " '583': 'units',\n",
       " '584': 'contrast',\n",
       " '585': 'sensitivity',\n",
       " '586': 'long-range',\n",
       " '587': 'efficiency',\n",
       " '588': 'robustness',\n",
       " '589': 'natural',\n",
       " '590': 'descent',\n",
       " '591': 'decision',\n",
       " '592': 'trees',\n",
       " '593': 'dnf:',\n",
       " '594': 'does',\n",
       " '595': 'matter?',\n",
       " '596': 'missing',\n",
       " '597': 'blood',\n",
       " '598': 'glucose',\n",
       " '599': 'canonical',\n",
       " '600': 'distortion',\n",
       " '601': 'measure',\n",
       " '602': 'feature',\n",
       " '603': '1-nn',\n",
       " '604': 'monotonic',\n",
       " '605': 'automatic',\n",
       " '606': 'phase-based',\n",
       " '607': 'photoreceptor',\n",
       " '608': 'sensitive',\n",
       " '609': 'small',\n",
       " '610': 'changes',\n",
       " '611': 'intensity',\n",
       " '612': 'melonet',\n",
       " '613': 'nets',\n",
       " '614': 'inventing',\n",
       " '615': 'baroque-style',\n",
       " '616': 'chorale',\n",
       " '617': 'variations',\n",
       " '618': 'detection',\n",
       " '619': 'first',\n",
       " '620': 'second',\n",
       " '621': 'order',\n",
       " '622': 'bidirectional',\n",
       " '623': 'retrieval',\n",
       " '624': 'asymptotic',\n",
       " '625': 'convergence-rate',\n",
       " '626': 'q-learning',\n",
       " '627': 'heuristic',\n",
       " '628': 'ranking',\n",
       " '629': 'hypotheses',\n",
       " '630': 'sets',\n",
       " '631': '000-neuron',\n",
       " '632': 'million',\n",
       " '633': '7-bit',\n",
       " '634': 'physical',\n",
       " '635': 'interconnections',\n",
       " '636': 'sweeping',\n",
       " '637': 'hinge',\n",
       " '638': 'encoding',\n",
       " '639': 'geometric',\n",
       " '640': 'invariances',\n",
       " '641': 'higher-order',\n",
       " '642': 'inhibitory',\n",
       " '643': 'rectified',\n",
       " '644': 'distribution',\n",
       " '645': 'complex',\n",
       " '646': 'cells',\n",
       " '647': 'awake',\n",
       " '648': 'macaque',\n",
       " '649': 'during',\n",
       " '650': 'viewing',\n",
       " '651': 'cooperative',\n",
       " '652': 'selecting',\n",
       " '653': 'weighting',\n",
       " '654': 'factors',\n",
       " '655': 'logarithmic',\n",
       " '656': 'opinion',\n",
       " '657': 'pools',\n",
       " '658': 'hippocampal',\n",
       " '659': 'incremental',\n",
       " '660': 'nearest',\n",
       " '661': 'neighbor',\n",
       " '662': 'expert',\n",
       " '663': 'preferences',\n",
       " '664': 'storage',\n",
       " '665': 'capacity',\n",
       " '666': 'fully-connected',\n",
       " '667': 'generic',\n",
       " '668': 'event',\n",
       " '669': 'related',\n",
       " '670': 'brain',\n",
       " '671': 'potentials',\n",
       " '672': 'passive',\n",
       " '673': 'shared',\n",
       " '674': 'element',\n",
       " '675': 'electrical',\n",
       " '676': 'cochlea',\n",
       " '677': 'annealed',\n",
       " '678': 'map',\n",
       " '679': 'factorizing',\n",
       " '680': 'multivariate',\n",
       " '681': 'adaptation',\n",
       " '682': 'motor',\n",
       " '683': 'periodic',\n",
       " '684': 'attractors',\n",
       " '685': 'olfactory',\n",
       " '686': 'regularization:',\n",
       " '687': 'one-dimensional',\n",
       " '688': 'general',\n",
       " '689': 'purpose',\n",
       " '690': 'chip:',\n",
       " '691': 'signals',\n",
       " '692': 'neighboring',\n",
       " '693': 'tetrode',\n",
       " '694': 'recordings',\n",
       " '695': 'formation',\n",
       " '696': 'scene',\n",
       " '697': 'environments:',\n",
       " '698': 'cell',\n",
       " '699': 'synthetic',\n",
       " '700': 'radar',\n",
       " '701': 'regularisation',\n",
       " '702': 'revolution:',\n",
       " '703': 'graphs',\n",
       " '704': 'cycles',\n",
       " '705': 'color',\n",
       " '706': 'nonparametric',\n",
       " '707': 'model-based',\n",
       " '708': 'preprocessing',\n",
       " '709': 'non-gaussian',\n",
       " '710': 'partially',\n",
       " '711': 'observable',\n",
       " '712': 'short-term',\n",
       " '713': 'multiplication',\n",
       " '714': 'self',\n",
       " '715': 'organizing',\n",
       " '716': 'classifier',\n",
       " '717': 'free',\n",
       " '718': 'pomdps',\n",
       " '719': 'coordinate',\n",
       " '720': 'transformation',\n",
       " '721': 'hand',\n",
       " '722': 'position',\n",
       " '723': 'feedback',\n",
       " '724': 'controller',\n",
       " '725': 'change',\n",
       " '726': 'norm',\n",
       " '727': 'correlational',\n",
       " '728': 'strength',\n",
       " '729': 'algebra',\n",
       " '730': 'connections',\n",
       " '731': 'outcomes',\n",
       " '732': 'equivalence',\n",
       " '733': 'ridge',\n",
       " '734': 'least',\n",
       " '735': 'absolute',\n",
       " '736': 'shrinkage',\n",
       " '737': 'call-based',\n",
       " '738': 'fraud',\n",
       " '739': 'communication',\n",
       " '740': 'regime-switching',\n",
       " '741': 'replicator',\n",
       " '742': 'equations,',\n",
       " '743': 'maximal',\n",
       " '744': 'cliques,',\n",
       " '745': 'graph',\n",
       " '746': 'isomorphism',\n",
       " '747': 'convergence',\n",
       " '748': 'rates',\n",
       " '749': 'search:',\n",
       " '750': 'detecting',\n",
       " '751': 'contours',\n",
       " '752': 'almost',\n",
       " '753': 'vc',\n",
       " '754': 'dimension',\n",
       " '755': 'piecewise',\n",
       " '756': 'polynomial',\n",
       " '757': 'simulation',\n",
       " '758': 'measurement',\n",
       " '759': 'generated',\n",
       " '760': 'generative',\n",
       " '761': 'discriminative',\n",
       " '762': 'classifiers',\n",
       " '763': 'smem',\n",
       " '764': 'mixture',\n",
       " '765': 'orientation,',\n",
       " '766': 'scale,',\n",
       " '767': 'discontinuity',\n",
       " '768': 'emergent',\n",
       " '769': 'properties',\n",
       " '770': 'illusory',\n",
       " '771': 'shape',\n",
       " '772': 'finite-sample',\n",
       " '773': 'indirect',\n",
       " '774': 'fisher',\n",
       " '775': 'scoring',\n",
       " '776': 'modes',\n",
       " '777': 'inference',\n",
       " '778': 'state',\n",
       " '779': 'what',\n",
       " '780': 'gives',\n",
       " '781': 'generalization?',\n",
       " '782': 'canceling',\n",
       " '783': 'neuro-chip',\n",
       " '784': 'on-chip',\n",
       " '785': 'capability',\n",
       " '786': 'intracellular',\n",
       " '787': 'calcium',\n",
       " '788': 'modulation',\n",
       " '789': 'discrimination',\n",
       " '790': 'psychophysics',\n",
       " '791': 'reproduced',\n",
       " '792': 'quantitative',\n",
       " '793': 'chip',\n",
       " '794': 'comparing',\n",
       " '795': 'biases',\n",
       " '796': 'graphical',\n",
       " '797': 'recognizing',\n",
       " '798': 'barycentric',\n",
       " '799': 'interpolators',\n",
       " '800': 'k-winners-take-all',\n",
       " '801': 'instance-independent',\n",
       " '802': 'enhance',\n",
       " '803': 'qp',\n",
       " '804': 'sparseness',\n",
       " '805': 'semi-supervised',\n",
       " '806': 'macro-actions',\n",
       " '807': 'phase',\n",
       " '808': 'diagram',\n",
       " '809': 'sequence-storing',\n",
       " '810': 'collective',\n",
       " '811': 'intelligence',\n",
       " '812': 'route',\n",
       " '813': 'internet',\n",
       " '814': 'global',\n",
       " '815': 'optimisation',\n",
       " '816': 'sampling',\n",
       " '817': 'analyzing',\n",
       " '818': 'landscapes',\n",
       " '819': 'tv',\n",
       " '820': 'compression',\n",
       " '821': 'hopfield',\n",
       " '822': 'type',\n",
       " '823': 'shrinkage:',\n",
       " '824': 'denoising',\n",
       " '825': 'likelihood',\n",
       " '826': 'integrated',\n",
       " '827': 'sensor',\n",
       " '828': 'optical',\n",
       " '829': 'flow',\n",
       " '830': 'singular',\n",
       " '831': 'points',\n",
       " '832': 'by-product',\n",
       " '833': 'regularization',\n",
       " '834': 'wavelet',\n",
       " '835': 'unsupervised',\n",
       " '836': 'clustering:',\n",
       " '837': 'parameters',\n",
       " '838': 'observations',\n",
       " '839': 'links',\n",
       " '840': 'components',\n",
       " '841': 'higher',\n",
       " '842': 'statistics',\n",
       " '843': 'dynamic,',\n",
       " '844': 'non-local',\n",
       " '845': 'bindings',\n",
       " '846': 'inferencing',\n",
       " '847': 'localist',\n",
       " '848': 'language',\n",
       " '849': 'understanding',\n",
       " '850': 'rate',\n",
       " '851': 'massively',\n",
       " '852': 'self-tuning',\n",
       " '853': 'context-free',\n",
       " '854': 'parser',\n",
       " '855': 'resonance',\n",
       " '856': 'interaction',\n",
       " '857': 'spike-based',\n",
       " '858': 'stabilization',\n",
       " '859': 'programmable',\n",
       " '860': 'computer',\n",
       " '861': 'simulator',\n",
       " '862': 'environment',\n",
       " '863': 'nonstationary',\n",
       " '864': 'factor',\n",
       " '865': 'structured',\n",
       " '866': 'graded',\n",
       " '867': 'grammaticality',\n",
       " '868': 'fractal',\n",
       " '869': 'thin-plate',\n",
       " '870': 'surface',\n",
       " '871': 'interpolation',\n",
       " '872': 'sensory-motor',\n",
       " '873': 'barn',\n",
       " '874': 'owl',\n",
       " '875': 'windows',\n",
       " '876': 'learn',\n",
       " '877': 'cmu',\n",
       " '878': 'direct-drive',\n",
       " '879': 'arm',\n",
       " '880': 'ii',\n",
       " '881': 'potential',\n",
       " '882': 'boosters?',\n",
       " '883': 'robust',\n",
       " '884': 'offline',\n",
       " '885': 'star',\n",
       " '886': 'spacecraft',\n",
       " '887': 'attitude',\n",
       " '888': 'determination',\n",
       " '889': 'effective',\n",
       " '890': 'requires',\n",
       " '891': 'remodeling',\n",
       " '892': 'hebbian',\n",
       " '893': 'visualization',\n",
       " '894': 'selection:',\n",
       " '895': 'nongaussian',\n",
       " '896': 'resolution',\n",
       " '897': 'enhancement',\n",
       " '898': 'sensory',\n",
       " '899': 'representation',\n",
       " '900': 'limited-interconnect,',\n",
       " '901': 'ic',\n",
       " '902': 'boltzmann',\n",
       " '903': 'perceptron',\n",
       " '904': 'network:',\n",
       " '905': 'fixed',\n",
       " '906': 'point',\n",
       " '907': 'genesis:',\n",
       " '908': 'simulating',\n",
       " '909': 'further',\n",
       " '910': 'visually-guided',\n",
       " '911': 'reaching:',\n",
       " '912': 'making',\n",
       " '913': 'murphy',\n",
       " '914': 'smarter',\n",
       " '915': 'receivers',\n",
       " '916': 'access-communications',\n",
       " '917': 'non-negative',\n",
       " '918': 'factorization',\n",
       " '919': 'pulse-firing',\n",
       " '920': 'factored',\n",
       " '921': 'semi-tied',\n",
       " '922': 'covariance',\n",
       " '923': 'matrices',\n",
       " '924': 'systems:',\n",
       " '925': 'mapping',\n",
       " '926': 'contour-map',\n",
       " '927': 'weak',\n",
       " '928': 'learners',\n",
       " '929': 'improved',\n",
       " '930': 'boosting',\n",
       " '931': 'weight',\n",
       " '932': 'synthesis',\n",
       " '933': 'converges',\n",
       " '934': 'region',\n",
       " '935': 'variational',\n",
       " '936': 'mean-field',\n",
       " '937': 'hmm',\n",
       " '938': 'probabilistic',\n",
       " '939': 'semantic',\n",
       " '940': 'video',\n",
       " '941': 'indexing',\n",
       " '942': 'clustering',\n",
       " '943': 'association',\n",
       " '944': 'nanostructures',\n",
       " '945': 'lead',\n",
       " '946': 'characterizing',\n",
       " '947': 'gain',\n",
       " '948': 'spike-triggered',\n",
       " '949': 'jeffreys',\n",
       " '950': 'prior',\n",
       " '951': 'days',\n",
       " '952': 'kanerva',\n",
       " '953': 'exponential',\n",
       " '954': 'audio-visual',\n",
       " '955': 'population',\n",
       " '956': 'parsing',\n",
       " '957': 'phonological',\n",
       " '958': 'loop:',\n",
       " '959': 'comparisons',\n",
       " '960': 'three',\n",
       " '961': 'real-world',\n",
       " '962': 'heading',\n",
       " '963': 'escaping',\n",
       " '964': 'convex',\n",
       " '965': 'hull',\n",
       " '966': 'extrapolated',\n",
       " '967': 'group',\n",
       " '968': 'theory:',\n",
       " '969': 'grounding',\n",
       " '970': 'robotics',\n",
       " '971': 'linear-time',\n",
       " '972': 'hmms',\n",
       " '973': 'kernel',\n",
       " '974': 'logistic',\n",
       " '975': 'import',\n",
       " '976': 'modulatory',\n",
       " '977': 'spatial',\n",
       " '978': 'intransitive',\n",
       " '979': 'likelihood-ratio',\n",
       " '980': 'neurodynamics',\n",
       " '981': 'drug',\n",
       " '982': 'process',\n",
       " '983': 'architectures',\n",
       " '984': 'multi-speaker',\n",
       " '985': 'time-alignment',\n",
       " '986': 'chips',\n",
       " '987': 'hundreds',\n",
       " '988': 'high-capacity',\n",
       " '989': 'circuits',\n",
       " '990': 'input/output',\n",
       " '991': 'compartment',\n",
       " '992': 'membranes',\n",
       " '993': 'greedy',\n",
       " '994': 'importance',\n",
       " '995': 'massive',\n",
       " '996': 'take',\n",
       " '997': 'concurrent',\n",
       " '998': 'actions',\n",
       " '999': 'development',\n",
       " ...}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(model, seq, maxLen, num_iteration, idx2word):\n",
    "    '''\n",
    "    Prediction for a given sequence. \n",
    "    \n",
    "    Parameters:\n",
    "    ===========\n",
    "    1)model: rnn model\n",
    "    2)seq: a single abstract, should be a vector of length 250\n",
    "    3)maxLen: maximum length of predicted title\n",
    "    4)idx2word: dictionary for index to word\n",
    "    '''\n",
    "    \n",
    "    #cache list of prediction\n",
    "    prediction = list()\n",
    "    #initiate title to be a vector of zeros\n",
    "    init = np.zeros(maxLen)\n",
    "    \n",
    "    #for maximum prediction length\n",
    "    for i in range(num_iteration):\n",
    "        #get prediction probabilities for all unique words\n",
    "        predRNN = model.predict([np.reshape(seq, (1, 250)), init.reshape(1, 250)])\n",
    "        #greedy mode prediction\n",
    "        #update next title vector to be the predicted vector\n",
    "        init = np.argmax(predRNN, axis = 2)\n",
    "        #get probabilities of all unique words\n",
    "        pVec = predRNN[0, 0, :]\n",
    "        #get the word with maximum predicted probability as the predicted words\n",
    "        idx = np.argmax(pVec)\n",
    "        #index to word\n",
    "        word = idx2word[str(idx)]\n",
    "        #if eos tag is predicted\n",
    "        #break out of loop\n",
    "        if idx == 1:\n",
    "            break\n",
    "        prediction.append(word)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check prediction \n",
    "check = testX.copy()\n",
    "check = sequence.pad_sequences(check, 250, value = word2idx['_'], \n",
    "                               padding = 'pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dual',\n",
       " 'inhibitory',\n",
       " 'mechanisms',\n",
       " 'for',\n",
       " 'definition',\n",
       " 'of',\n",
       " 'receptive',\n",
       " 'field',\n",
       " 'characteristics',\n",
       " 'in',\n",
       " 'a',\n",
       " 'cat',\n",
       " 'striate',\n",
       " 'cortex']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of seq2seq prediction\n",
    "#true title\n",
    "[idx2word[str(m)] for m in testY[40]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " '_',\n",
       " 'in',\n",
       " 'single',\n",
       " 'cells',\n",
       " 'of',\n",
       " 'the',\n",
       " 'cat',\n",
       " 'striate',\n",
       " 'cortex,',\n",
       " 'lateral',\n",
       " 'inhibition',\n",
       " 'across',\n",
       " 'orientation',\n",
       " 'and/or',\n",
       " 'spatial',\n",
       " 'frequency',\n",
       " 'is',\n",
       " 'found',\n",
       " 'to',\n",
       " 'enhance',\n",
       " 'pre-existing',\n",
       " 'biases.',\n",
       " 'a',\n",
       " 'contrast-dependent',\n",
       " 'but',\n",
       " 'spatially',\n",
       " 'non-selective',\n",
       " 'inhibitory',\n",
       " 'component',\n",
       " 'is',\n",
       " 'also',\n",
       " 'found.',\n",
       " 'stimulation',\n",
       " 'with',\n",
       " 'ascending',\n",
       " 'and',\n",
       " 'descending',\n",
       " 'contrasts',\n",
       " 'reveals',\n",
       " 'the',\n",
       " 'latter',\n",
       " 'as',\n",
       " 'a',\n",
       " 'response',\n",
       " 'hysteresis',\n",
       " 'that',\n",
       " 'is',\n",
       " 'sensitive,',\n",
       " 'powerful',\n",
       " 'and',\n",
       " 'rapid,',\n",
       " 'suggesting',\n",
       " 'that',\n",
       " 'it',\n",
       " 'is',\n",
       " 'active',\n",
       " 'in',\n",
       " 'day-to-day',\n",
       " 'vision.',\n",
       " 'both',\n",
       " 'forms',\n",
       " 'of',\n",
       " 'inhibition',\n",
       " 'are',\n",
       " 'not',\n",
       " 'recurrent',\n",
       " 'but',\n",
       " 'are',\n",
       " 'rather',\n",
       " 'network',\n",
       " 'properties.',\n",
       " 'these',\n",
       " 'findings',\n",
       " 'suggest',\n",
       " 'two',\n",
       " 'fundamental',\n",
       " 'inhibitory',\n",
       " 'mechanisms:',\n",
       " 'a',\n",
       " 'global',\n",
       " 'mechanism',\n",
       " 'that',\n",
       " 'limits',\n",
       " 'dynamic',\n",
       " 'range',\n",
       " 'and',\n",
       " 'creates',\n",
       " 'spatial',\n",
       " 'selectivity',\n",
       " 'through',\n",
       " 'thresholding',\n",
       " 'and',\n",
       " 'a',\n",
       " 'local',\n",
       " 'mechanism',\n",
       " 'that',\n",
       " 'specifically',\n",
       " 'refines',\n",
       " 'spatial',\n",
       " 'filter',\n",
       " 'properties.',\n",
       " 'analysis',\n",
       " 'of',\n",
       " 'burst',\n",
       " 'patterns',\n",
       " 'in',\n",
       " 'spike',\n",
       " 'trains',\n",
       " 'demonstrates',\n",
       " 'that',\n",
       " 'these',\n",
       " 'two',\n",
       " 'mechanisms',\n",
       " 'have',\n",
       " 'unique',\n",
       " 'physiological',\n",
       " 'origins.',\n",
       " '<ign>',\n",
       " '<ign>']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#true abstract\n",
    "[idx2word[str(m)] for m in check[40]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neural',\n",
       " 'network',\n",
       " 'dynamical',\n",
       " 'models',\n",
       " 'of',\n",
       " 'brain',\n",
       " 'connectivity',\n",
       " 'of',\n",
       " 'brain',\n",
       " 'connectivity',\n",
       " 'of',\n",
       " 'brain',\n",
       " 'connectivity',\n",
       " 'of',\n",
       " 'brain',\n",
       " 'connectivity',\n",
       " 'of',\n",
       " 'brain',\n",
       " 'connectivity',\n",
       " 'of']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prediction\n",
    "check_pred = getPredictions(rnn, check[40], 250, 20, idx2word)\n",
    "check_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # generate target given source sequence\n",
    "# def predict_sequence(infenc, infdec, source, n_steps, cardinality):\n",
    "#     # encode\n",
    "#     state = infenc.predict(np.reshape(source,(1,250)))\n",
    "#     #start of sequence input\n",
    "#     target_seq = np.array([0.0 for _ in range(cardinality)]).reshape(1, 1, cardinality)\n",
    "# #     target_seq = np.zeros((source,1, 250))\n",
    "#     # collect predictions\n",
    "#     output = list()\n",
    "#     for t in range(n_steps):\n",
    "#         # predict next char\n",
    "#         yhat, h, c = infdec.predict([target_seq] + state)\n",
    "#         # store prediction\n",
    "#         output.append(yhat[0,0,:])\n",
    "#         # update state\n",
    "#         state = [h, c]\n",
    "#         # update target sequence\n",
    "#         target_seq = yhat\n",
    "#     return np.array(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QrsGXLs3x0Xc"
   },
   "outputs": [],
   "source": [
    "# #single layger LSTM \n",
    "# def encoder_decoder(genTrain, genVal, mode = 'fit', num_epochs = 1, \n",
    "#                     en_shape = aMaxLen, de_shape = tMaxLen):\n",
    "    \n",
    "# #     print('Encoder_Decoder LSTM...')\n",
    "   \n",
    "# #     \"\"\"__encoder___\"\"\"\n",
    "# #     encoder_inputs = Input(shape=(en_shape,), name='inputE')\n",
    "# #     print(encoder_inputs)\n",
    "    \n",
    "# #     #APPLY EMBEDDING LAYER. https://keras.io/layers/embeddings/       \n",
    "# #     input_emb = Embedding(nUnique, embeddDim,\n",
    "# #                           input_length = aMaxLen,\n",
    "# #                           W_regularizer = regularizer, dropout = p_emb, \n",
    "# #                           weights=[embeddMatrix], mask_zero = True,\n",
    "# #                           name='embedding_1')\n",
    "    \n",
    "# #     #ENCODER LSTM - FORWARD   https://keras.io/layers/recurrent/  \n",
    "# #     encoder_LSTM = LSTM(hidden_units, dropout_U = 0.2, dropout_W = 0.2 ,return_state=True)\n",
    "# #     encoder_LSTM_rev = LSTM(hidden_units,return_state=True,go_backwards=True)\n",
    "    \n",
    "# #     #ENCODER LSTM - REVERSE \n",
    "# #     encoder_outputsR, state_hR, state_cR = encoder_LSTM_rev(input_emb(encoder_inputs))\n",
    "# #     encoder_outputs, state_h, state_c = encoder_LSTM(input_emb(encoder_inputs))\n",
    "        \n",
    "# #     state_hfinal=Add()([state_h,state_hR])\n",
    "# #     state_cfinal=Add()([state_c,state_cR])\n",
    "    \n",
    "# #     encoder_states = [state_hfinal,state_cfinal]\n",
    "    \n",
    "#     \"\"\"____decoder___\"\"\"\n",
    "#     #Input to the decoder would be the summary(headline) sequence starting from ~ character.\n",
    "#     decoder_inputs = Input(shape=(de_shape,), name = 'inputD')\n",
    "# #     decoder_inputs = Input(shape=(en_shape,))\n",
    "#     print(decoder_inputs)\n",
    "      \n",
    "#     decoder_LSTM = LSTM(hidden_units,return_sequences=True,return_state=True)\n",
    "#     decoder_outputs, _, _ = decoder_LSTM(input_emb(decoder_inputs),initial_state=encoder_states) \n",
    "# #     decoder_dense = Dense(de_shape,activation='linear')\n",
    "    \n",
    "#     # Apply a dense layer that has vocab_size(40000) outputs which learns probability of each word when softmax is applied.\n",
    "#     # TimeDistributed is a wrapper for applying the same function over all the time step outputs. \n",
    "#     # Refer https://keras.io/layers/wrappers/\n",
    "#     decoder_time_distributed = TimeDistributed(Dense(nUnique,\n",
    "#                                                      W_regularizer=regularizer, \n",
    "#                                                      b_regularizer=regularizer,\n",
    "#                                                      name = 'decoder_timedistributed'))\n",
    "#     activation = Activation('softmax', name = 'activation_1')\n",
    "#     decoder_outputs = activation(time_distributed(decoder_outputs))\n",
    "    \n",
    "#     #Model groups layers into an object with training and inference features.\n",
    "#     #https://www.tensorflow.org/api_docs/python/tf/keras/models/Model        \n",
    "#     model= Model(inputs=[encoder_inputs,decoder_inputs], outputs=decoder_outputs)\n",
    "    \n",
    "#     rmsprop = RMSprop(lr = learning_rate,clipnorm = clip_norm)\n",
    "    \n",
    "#     model.compile(loss='categorical_crossentropy',optimizer=rmsprop)\n",
    "    \n",
    "    \n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.fit_generator(genTrain,\n",
    "#                             steps_per_epoch = num_train_batches,\n",
    "#                             epochs=5,  #Try different epochs as hyperparameter \n",
    "#                             validation_data = genVal,\n",
    "#                             validation_steps = num_val_batches)\n",
    "    \n",
    "#     #_________________________INFERENCE MODE______________________________#  \n",
    "    \n",
    "#     encoder_model_inf = Model(encoder_inputs,encoder_states)\n",
    "    \n",
    "#     decoder_state_input_H = Input(shape=(hidden_units,))\n",
    "#     decoder_state_input_C = Input(shape=(hidden_units,)) \n",
    "#     decoder_state_inputs = [decoder_state_input_H, decoder_state_input_C]\n",
    "#     decoder_outputs, decoder_state_h, decoder_state_c = decoder_LSTM(input_emb(decoder_inputs),\n",
    "#                                                                      initial_state=decoder_state_inputs)\n",
    "#     decoder_states = [decoder_state_h, decoder_state_c]\n",
    "#     decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "#     decoder_model_inf= Model([decoder_inputs]+decoder_state_inputs,\n",
    "#                              [decoder_outputs]+decoder_states)\n",
    "    \n",
    "#     return model,encoder_model_inf,decoder_model_inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M_xodO1dx0Xe"
   },
   "outputs": [],
   "source": [
    "#let's try this\n",
    "# model = encoder_decoder(genTrain, genVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZuKtx7wKx0Xg"
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MxqF7dqZx0Xi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "rnn_model.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
